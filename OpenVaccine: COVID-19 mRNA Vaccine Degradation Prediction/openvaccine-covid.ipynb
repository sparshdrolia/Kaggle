{"cells":[{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import os\nimport json\nimport torch\nimport numpy as np \nimport pandas as pd\nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader\nfrom sklearn.preprocessing import OneHotEncoder, LabelEncoder\n","execution_count":8,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# train = pd.read_json('../input/stanford-covid-vaccine/train.json', lines=True)\n# train.head(3)","execution_count":39,"outputs":[{"output_type":"execute_result","execution_count":39,"data":{"text/plain":"   index            id                                           sequence  \\\n0      0  id_001f94081  GGAAAAGCUCUAAUAACAGGAGACUAGGACUACGUAUUUCUAGGUA...   \n1      1  id_0049f53ba  GGAAAAAGCGCGCGCGGUUAGCGCGCGCUUUUGCGCGCGCUGUACC...   \n2      2  id_006f36f57  GGAAAGUGCUCAGAUAAGCUAAGCUCGAAUAGCAAUCGAAUAGAAU...   \n\n                                           structure  \\\n0  .....((((((.......)))).)).((.....((..((((((......   \n1  .....(((((((((((((((((((((((....)))))))))).)))...   \n2  .....((((.((.....((((.(((.....)))..((((......)...   \n\n                                 predicted_loop_type  signal_to_noise  \\\n0  EEEEESSSSSSHHHHHHHSSSSBSSXSSIIIIISSIISSSSSSHHH...            6.894   \n1  EEEEESSSSSSSSSSSSSSSSSSSSSSSHHHHSSSSSSSSSSBSSS...            0.193   \n2  EEEEESSSSISSIIIIISSSSMSSSHHHHHSSSMMSSSSHHHHHHS...            8.800   \n\n   SN_filter  seq_length  seq_scored  \\\n0          1         107          68   \n1          0         107          68   \n2          1         107          68   \n\n                                    reactivity_error  \\\n0  [0.1359, 0.20700000000000002, 0.1633, 0.1452, ...   \n1  [2.8272, 2.8272, 2.8272, 4.7343, 2.5676, 2.567...   \n2  [0.0931, 0.13290000000000002, 0.11280000000000...   \n\n                                   deg_error_Mg_pH10  \\\n0  [0.26130000000000003, 0.38420000000000004, 0.1...   \n1  [73705.3985, 73705.3985, 73705.3985, 73705.398...   \n2  [0.1365, 0.2237, 0.1812, 0.1333, 0.1148, 0.160...   \n\n                                      deg_error_pH10  \\\n0  [0.2631, 0.28600000000000003, 0.0964, 0.1574, ...   \n1  [10.1986, 9.2418, 5.0933, 5.0933, 5.0933, 5.09...   \n2  [0.17020000000000002, 0.178, 0.111, 0.091, 0.0...   \n\n                                    deg_error_Mg_50C  \\\n0  [0.1501, 0.275, 0.0947, 0.18660000000000002, 0...   \n1  [16.6174, 13.868, 8.1968, 8.1968, 8.1968, 8.19...   \n2  [0.1033, 0.1464, 0.1126, 0.09620000000000001, ...   \n\n                                       deg_error_50C  \\\n0  [0.2167, 0.34750000000000003, 0.188, 0.2124, 0...   \n1  [15.4857, 7.9596, 13.3957, 5.8777, 5.8777, 5.8...   \n2  [0.14980000000000002, 0.1761, 0.1517, 0.116700...   \n\n                                          reactivity  \\\n0  [0.3297, 1.5693000000000001, 1.1227, 0.8686, 0...   \n1  [0.0, 0.0, 0.0, 2.2965, 0.0, 0.0, 0.0, 0.0, 0....   \n2  [0.44820000000000004, 1.4822, 1.1819, 0.743400...   \n\n                                         deg_Mg_pH10  \\\n0  [0.7556, 2.983, 0.2526, 1.3789, 0.637600000000...   \n1  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n2  [0.2504, 1.4021, 0.9804, 0.49670000000000003, ...   \n\n                                            deg_pH10  \\\n0  [2.3375, 3.5060000000000002, 0.3008, 1.0108, 0...   \n1  [4.947, 4.4523, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n2  [2.243, 2.9361, 1.0553, 0.721, 0.6396000000000...   \n\n                                          deg_Mg_50C  \\\n0  [0.35810000000000003, 2.9683, 0.2589, 1.4552, ...   \n1  [4.8511, 4.0426, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...   \n2  [0.5163, 1.6823000000000001, 1.0426, 0.7902, 0...   \n\n                                             deg_50C  \n0  [0.6382, 3.4773, 0.9988, 1.3228, 0.78770000000...  \n1  [7.6692, 0.0, 10.9561, 0.0, 0.0, 0.0, 0.0, 0.0...  \n2  [0.9501000000000001, 1.7974999999999999, 1.499...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>index</th>\n      <th>id</th>\n      <th>sequence</th>\n      <th>structure</th>\n      <th>predicted_loop_type</th>\n      <th>signal_to_noise</th>\n      <th>SN_filter</th>\n      <th>seq_length</th>\n      <th>seq_scored</th>\n      <th>reactivity_error</th>\n      <th>deg_error_Mg_pH10</th>\n      <th>deg_error_pH10</th>\n      <th>deg_error_Mg_50C</th>\n      <th>deg_error_50C</th>\n      <th>reactivity</th>\n      <th>deg_Mg_pH10</th>\n      <th>deg_pH10</th>\n      <th>deg_Mg_50C</th>\n      <th>deg_50C</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>id_001f94081</td>\n      <td>GGAAAAGCUCUAAUAACAGGAGACUAGGACUACGUAUUUCUAGGUA...</td>\n      <td>.....((((((.......)))).)).((.....((..((((((......</td>\n      <td>EEEEESSSSSSHHHHHHHSSSSBSSXSSIIIIISSIISSSSSSHHH...</td>\n      <td>6.894</td>\n      <td>1</td>\n      <td>107</td>\n      <td>68</td>\n      <td>[0.1359, 0.20700000000000002, 0.1633, 0.1452, ...</td>\n      <td>[0.26130000000000003, 0.38420000000000004, 0.1...</td>\n      <td>[0.2631, 0.28600000000000003, 0.0964, 0.1574, ...</td>\n      <td>[0.1501, 0.275, 0.0947, 0.18660000000000002, 0...</td>\n      <td>[0.2167, 0.34750000000000003, 0.188, 0.2124, 0...</td>\n      <td>[0.3297, 1.5693000000000001, 1.1227, 0.8686, 0...</td>\n      <td>[0.7556, 2.983, 0.2526, 1.3789, 0.637600000000...</td>\n      <td>[2.3375, 3.5060000000000002, 0.3008, 1.0108, 0...</td>\n      <td>[0.35810000000000003, 2.9683, 0.2589, 1.4552, ...</td>\n      <td>[0.6382, 3.4773, 0.9988, 1.3228, 0.78770000000...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>id_0049f53ba</td>\n      <td>GGAAAAAGCGCGCGCGGUUAGCGCGCGCUUUUGCGCGCGCUGUACC...</td>\n      <td>.....(((((((((((((((((((((((....)))))))))).)))...</td>\n      <td>EEEEESSSSSSSSSSSSSSSSSSSSSSSHHHHSSSSSSSSSSBSSS...</td>\n      <td>0.193</td>\n      <td>0</td>\n      <td>107</td>\n      <td>68</td>\n      <td>[2.8272, 2.8272, 2.8272, 4.7343, 2.5676, 2.567...</td>\n      <td>[73705.3985, 73705.3985, 73705.3985, 73705.398...</td>\n      <td>[10.1986, 9.2418, 5.0933, 5.0933, 5.0933, 5.09...</td>\n      <td>[16.6174, 13.868, 8.1968, 8.1968, 8.1968, 8.19...</td>\n      <td>[15.4857, 7.9596, 13.3957, 5.8777, 5.8777, 5.8...</td>\n      <td>[0.0, 0.0, 0.0, 2.2965, 0.0, 0.0, 0.0, 0.0, 0....</td>\n      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n      <td>[4.947, 4.4523, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n      <td>[4.8511, 4.0426, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n      <td>[7.6692, 0.0, 10.9561, 0.0, 0.0, 0.0, 0.0, 0.0...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>id_006f36f57</td>\n      <td>GGAAAGUGCUCAGAUAAGCUAAGCUCGAAUAGCAAUCGAAUAGAAU...</td>\n      <td>.....((((.((.....((((.(((.....)))..((((......)...</td>\n      <td>EEEEESSSSISSIIIIISSSSMSSSHHHHHSSSMMSSSSHHHHHHS...</td>\n      <td>8.800</td>\n      <td>1</td>\n      <td>107</td>\n      <td>68</td>\n      <td>[0.0931, 0.13290000000000002, 0.11280000000000...</td>\n      <td>[0.1365, 0.2237, 0.1812, 0.1333, 0.1148, 0.160...</td>\n      <td>[0.17020000000000002, 0.178, 0.111, 0.091, 0.0...</td>\n      <td>[0.1033, 0.1464, 0.1126, 0.09620000000000001, ...</td>\n      <td>[0.14980000000000002, 0.1761, 0.1517, 0.116700...</td>\n      <td>[0.44820000000000004, 1.4822, 1.1819, 0.743400...</td>\n      <td>[0.2504, 1.4021, 0.9804, 0.49670000000000003, ...</td>\n      <td>[2.243, 2.9361, 1.0553, 0.721, 0.6396000000000...</td>\n      <td>[0.5163, 1.6823000000000001, 1.0426, 0.7902, 0...</td>\n      <td>[0.9501000000000001, 1.7974999999999999, 1.499...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"Setting constant variables"},{"metadata":{"trusted":true},"cell_type":"code","source":"EPOCHS = 10\nBATCH_SIZE = 200\nLR = 0.01\nFEATURE_SIZE = 21","execution_count":4,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"One hot encoding function for a given string and its categories(in a list)\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"def one_hot(categories, string):\n    encoding = np.zeros((len(string), len(categories)))\n    \n    for idx, char in enumerate(string):\n        encoding[idx, categories.index(char)] = 1\n    return encoding","execution_count":25,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"one hot encoding for one row of train/test, binding and returning; returns a matrix of 107x14"},{"metadata":{"trusted":true},"cell_type":"code","source":"def featurize(entity):\n    sequence = one_hot(list('ACGU'), entity['sequence'])\n    structure = one_hot(list('.()'), entity['structure'])\n    loop_type = one_hot(list('BEHIMSX'), entity['predicted_loop_type'])\n    \n    features = np.hstack([sequence, structure, loop_type])\n    return features","execution_count":31,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# p = featurize(train.iloc[0])\n# len(p)","execution_count":45,"outputs":[{"output_type":"execute_result","execution_count":45,"data":{"text/plain":"107"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"OKay, so this function takes the feature = featurize(string - \"AACCGGYUU...\") which is a 107x14 matrix\nbasically what we have to do is consider sub sequences of same length for out dataset, we can take the whole string too, but there is no need for that. so we take the aage k and peeche k 10 elements of string (EG\"AACC...\") for every element in string and make it the new string. we also add padding incase there arent 10 elements at the back or front in the below funstion.......\nfinallly we return a 21 length sub-string with/without padding in one hot form (as we took it) ie 21x14 string is returned"},{"metadata":{"trusted":true},"cell_type":"code","source":"def char_encode(index, features, feature_size):\n    half_size = (feature_size - 1) // 2\n    \n    if index - half_size < 0:\n        char_features = features[:index+half_size+1]\n        padding = np.zeros((int(half_size - index), char_features.shape[1]))\n        char_features = np.vstack([padding, char_features])\n    elif index + half_size + 1 > len(features):\n        char_features = features[index-half_size:]\n        padding = np.zeros((int(half_size - (len(features) - index))+1, char_features.shape[1]))\n        char_features = np.vstack([char_features, padding])\n    else:\n        char_features = features[index-half_size:index+half_size+1]\n    \n    return char_features","execution_count":51,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class VaxDataset(Dataset):\n    def __init__(self, path, test=False):\n        self.path = path\n        self.test = test\n        self.features = []\n        self.targets = []\n        self.ids = []\n        self.load_data()\n        \n    def load_data(self):\n        with open(self.path, 'r') as text:         # read json file into text\n            for line in text:                      # gets one row of train/test at a time\n                records = json.loads(line)         # that one row is in records now\n                features = featurize(records)      # returns a 107x14 matrix --- only 3 rows --- diff for test\n                \n                for char_i in range(records['seq_scored']):                         # 68 --- diff for test\n                    char_features = char_encode(char_i, features, FEATURE_SIZE)     # get 21x14 matrix in char_features\n                    self.features.append(char_features)                             # append to N x 21 x 14\n                    self.ids.append('%s_%d' % (records['id'], char_i))              #actualId_size\n                    \n                if not self.test:                  # if its the train set, we need the targets\n                    targets = np.stack([records['reactivity'], records['deg_Mg_pH10'], records['deg_Mg_50C']], axis=1)\n                    self.targets.extend([targets[char_i] for char_i in range(records['seq_scored'])])\n                    \n    def __len__(self):\n        return len(self.features)\n    \n    def __getitem__(self, index):\n        if self.test:\n            return self.features[index], self.ids[index]\n        else:\n            return self.features[index], self.targets[index], self.ids[index]\n\n    ","execution_count":52,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_dataset = VaxDataset('../input/stanford-covid-vaccine/train.json')\ntrain_dataloader = DataLoader(train_dataset, BATCH_SIZE, shuffle=True, num_workers=4, pin_memory=True)","execution_count":53,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class Flatten(nn.Module):\n    def forward(self, x):\n        batch_size = x.shape[0]\n        return x.view(batch_size, -1)\n    \nclass VaxModel(nn.Module):\n    def __init__(self):\n        super(VaxModel, self).__init__()     #initializer\n        self.layers = nn.Sequential(\n            nn.Dropout(0.2),\n            nn.Conv1d(14, 32, 1, 1),\n            nn.PReLU(),\n            nn.BatchNorm1d(32),\n            nn.Dropout(0.2),\n            nn.Conv1d(32, 1, 1, 1),\n            nn.PReLU(),\n            Flatten(),\n            nn.Dropout(0.2),\n            nn.Linear(FEATURE_SIZE, 32),\n            nn.PReLU(),\n            nn.BatchNorm1d(32),\n            nn.Dropout(0.2),\n            nn.Linear(32, 3),\n        )\n        \n    def forward(self, features):\n        return self.layers(features)","execution_count":56,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = VaxModel()\noptimizer = torch.optim.Adam(model.parameters(), LR)\ncriterion = nn.MSELoss()","execution_count":57,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for epoch in range(EPOCHS):\n    losses = []\n    model.train()\n    for features, targets, ids in train_dataloader:\n        \n        features = features.permute(0,2,1).float()\n        \n        targets  = targets.float()\n        predictions = model(features)\n        loss = criterion(predictions, targets)\n        \n        for p in model.parameters():\n            p.grad = None\n        \n        loss.backward()\n        optimizer.step()\n        losses.append(loss.detach().numpy())\n    \n    avg_loss = float(np.mean(losses))\n    print(epoch, avg_loss)\n    \ntorch.save(model.state_dict(), 'weights.pth')","execution_count":58,"outputs":[{"output_type":"stream","text":"0 0.545386016368866\n1 0.5307008028030396\n2 0.5274965763092041\n3 0.527568519115448\n4 0.5276196599006653\n5 0.5273244976997375\n6 0.5268319845199585\n7 0.5261529088020325\n8 0.5259855389595032\n9 0.5267547965049744\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}