{"cells":[{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"\nimport warnings\nwarnings.filterwarnings('ignore')\n\n#the basics\nimport pandas as pd, numpy as np\nimport math, json, gc, random, os, sys\nfrom matplotlib import pyplot as plt\nfrom tqdm import tqdm\n\n#tensorflow deep learning basics\nimport tensorflow as tf\nimport tensorflow_addons as tfa\nimport tensorflow.keras.backend as K\nimport tensorflow.keras.layers as L\n\n#for model evaluation\nfrom sklearn.model_selection import train_test_split, KFold","execution_count":1,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#get comp data\ntrain = pd.read_json('/kaggle/input/stanford-covid-vaccine/train.json', lines=True)\ntest = pd.read_json('/kaggle/input/stanford-covid-vaccine/test.json', lines=True)\nsample_sub = pd.read_csv('/kaggle/input/stanford-covid-vaccine/sample_submission.csv')","execution_count":2,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#target columns\ntarget_cols = ['reactivity', 'deg_Mg_pH10', 'deg_pH10', 'deg_Mg_50C', 'deg_50C']","execution_count":3,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"token2int = {x:i for i, x in enumerate('().ACGUBEHIMSX')}","execution_count":4,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def preprocess_inputs(df, cols=['sequence', 'structure', 'predicted_loop_type']):\n    return np.transpose(\n        np.array(\n            df[cols]\n            .applymap(lambda seq: [token2int[x] for x in seq])\n            .values\n            .tolist()\n        ),\n        (0, 2, 1)\n    )","execution_count":5,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_inputs = preprocess_inputs(train[train.signal_to_noise > 1])\ntrain_labels = np.array(train[train.signal_to_noise > 1][target_cols].values.tolist()).transpose((0, 2, 1))","execution_count":6,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def MCRMSE(y_true, y_pred):\n    colwise_mse = tf.reduce_mean(tf.square(y_true - y_pred), axis=1)\n    return tf.reduce_mean(tf.sqrt(colwise_mse), axis=1)\n\n\n","execution_count":11,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def gru_layer(hidden_dim, dropout):\n    return tf.keras.layers.Bidirectional(\n                                tf.keras.layers.GRU(hidden_dim,\n                                dropout=dropout,\n                                return_sequences=True,\n                                kernel_initializer = 'orthogonal'))\n\ndef lstm_layer(hidden_dim, dropout):\n    return tf.keras.layers.Bidirectional(\n                                tf.keras.layers.LSTM(hidden_dim,\n                                dropout=dropout,\n                                return_sequences=True,\n                                kernel_initializer = 'orthogonal'))\n\ndef build_model(gru=1,seq_len=107, pred_len=68, dropout=0.5,\n                embed_dim=75, hidden_dim=128):\n    \n    inputs = tf.keras.layers.Input(shape=(seq_len, 3))\n\n    embed = tf.keras.layers.Embedding(input_dim=len(token2int), output_dim=embed_dim)(inputs)\n    reshaped = tf.reshape(\n        embed, shape=(-1, embed.shape[1],  embed.shape[2] * embed.shape[3]))\n    \n    reshaped = tf.keras.layers.SpatialDropout1D(.2)(reshaped)\n    \n    if gru==1:\n        hidden = gru_layer(hidden_dim, dropout)(reshaped)\n        hidden = gru_layer(hidden_dim, dropout)(hidden)\n        hidden = gru_layer(hidden_dim, dropout)(hidden)\n        \n    elif gru==0:\n        hidden = lstm_layer(hidden_dim, dropout)(reshaped)\n        hidden = lstm_layer(hidden_dim, dropout)(hidden)\n        hidden = lstm_layer(hidden_dim, dropout)(hidden)\n        \n    elif gru==3:\n        hidden = gru_layer(hidden_dim, dropout)(reshaped)\n        hidden = lstm_layer(hidden_dim, dropout)(hidden)\n        hidden = lstm_layer(hidden_dim, dropout)(hidden)\n        \n    elif gru==4:\n        hidden = lstm_layer(hidden_dim, dropout)(reshaped)\n        hidden = gru_layer(hidden_dim, dropout)(hidden)\n        hidden = gru_layer(hidden_dim, dropout)(hidden)\n    elif gru==5:\n        hidden = lstm_layer(hidden_dim, dropout)(reshaped)\n        hidden = gru_layer(hidden_dim, dropout)(hidden)\n        hidden = lstm_layer(hidden_dim, dropout)(reshaped)\n    \n    #only making predictions on the first part of each sequence\n    truncated = hidden[:, :pred_len]\n    \n    out = tf.keras.layers.Dense(5, activation='linear')(truncated)\n\n    model = tf.keras.Model(inputs=inputs, outputs=out)\n\n    #some optimizers\n    adam = tf.optimizers.Adam()\n    radam = tfa.optimizers.RectifiedAdam()\n    lookahead = tfa.optimizers.Lookahead(adam, sync_period=6)\n    ranger = tfa.optimizers.Lookahead(radam, sync_period=6)\n    \n    model.compile(optimizer = adam, loss=MCRMSE)\n    \n    return model","execution_count":13,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Training\n\n**Create train/val split now so both models are trained and evaluated on the same samples:**"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_inputs, val_inputs, train_labels, val_labels = train_test_split(train_inputs, train_labels,\n                                                                     test_size=.1, random_state=34)","execution_count":14,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"if tf.config.list_physical_devices('GPU') is not None:\n    print('Training on GPU')","execution_count":15,"outputs":[{"output_type":"stream","text":"Training on GPU\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"**We will use a simple learning rate callback for now:**"},{"metadata":{"trusted":true},"cell_type":"code","source":"lr_callback = tf.keras.callbacks.ReduceLROnPlateau()","execution_count":16,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 1. GRU"},{"metadata":{"trusted":true},"cell_type":"code","source":"gru = build_model(gru=1)\nsv_gru = tf.keras.callbacks.ModelCheckpoint('model_gru.h5')\n\nhistory_gru = gru.fit(\n    train_inputs, train_labels, \n    validation_data=(val_inputs,val_labels),\n    batch_size=64,\n    epochs=100,\n    callbacks=[lr_callback,sv_gru],\n    verbose = 2\n)\n\nprint(f\"Min training loss={min(history_gru.history['loss'])}, min validation loss={min(history_gru.history['val_loss'])}\")","execution_count":17,"outputs":[{"output_type":"stream","text":"Epoch 1/100\n27/27 - 3s - loss: 0.4683 - val_loss: 0.4208\nEpoch 2/100\n27/27 - 1s - loss: 0.4027 - val_loss: 0.3992\nEpoch 3/100\n27/27 - 1s - loss: 0.3868 - val_loss: 0.3834\nEpoch 4/100\n27/27 - 1s - loss: 0.3724 - val_loss: 0.3682\nEpoch 5/100\n27/27 - 1s - loss: 0.3583 - val_loss: 0.3572\nEpoch 6/100\n27/27 - 1s - loss: 0.3489 - val_loss: 0.3465\nEpoch 7/100\n27/27 - 1s - loss: 0.3413 - val_loss: 0.3411\nEpoch 8/100\n27/27 - 1s - loss: 0.3363 - val_loss: 0.3358\nEpoch 9/100\n27/27 - 1s - loss: 0.3324 - val_loss: 0.3358\nEpoch 10/100\n27/27 - 1s - loss: 0.3261 - val_loss: 0.3268\nEpoch 11/100\n27/27 - 1s - loss: 0.3223 - val_loss: 0.3206\nEpoch 12/100\n27/27 - 1s - loss: 0.3168 - val_loss: 0.3185\nEpoch 13/100\n27/27 - 1s - loss: 0.3128 - val_loss: 0.3114\nEpoch 14/100\n27/27 - 1s - loss: 0.3089 - val_loss: 0.3083\nEpoch 15/100\n27/27 - 1s - loss: 0.3052 - val_loss: 0.3043\nEpoch 16/100\n27/27 - 1s - loss: 0.3011 - val_loss: 0.3019\nEpoch 17/100\n27/27 - 1s - loss: 0.2995 - val_loss: 0.2976\nEpoch 18/100\n27/27 - 1s - loss: 0.2948 - val_loss: 0.2936\nEpoch 19/100\n27/27 - 1s - loss: 0.2908 - val_loss: 0.2908\nEpoch 20/100\n27/27 - 1s - loss: 0.2890 - val_loss: 0.2883\nEpoch 21/100\n27/27 - 1s - loss: 0.2858 - val_loss: 0.2848\nEpoch 22/100\n27/27 - 1s - loss: 0.2824 - val_loss: 0.2795\nEpoch 23/100\n27/27 - 1s - loss: 0.2798 - val_loss: 0.2787\nEpoch 24/100\n27/27 - 1s - loss: 0.2776 - val_loss: 0.2737\nEpoch 25/100\n27/27 - 1s - loss: 0.2750 - val_loss: 0.2728\nEpoch 26/100\n27/27 - 1s - loss: 0.2719 - val_loss: 0.2660\nEpoch 27/100\n27/27 - 1s - loss: 0.2686 - val_loss: 0.2688\nEpoch 28/100\n27/27 - 1s - loss: 0.2670 - val_loss: 0.2627\nEpoch 29/100\n27/27 - 2s - loss: 0.2638 - val_loss: 0.2594\nEpoch 30/100\n27/27 - 1s - loss: 0.2619 - val_loss: 0.2577\nEpoch 31/100\n27/27 - 1s - loss: 0.2610 - val_loss: 0.2571\nEpoch 32/100\n27/27 - 1s - loss: 0.2584 - val_loss: 0.2561\nEpoch 33/100\n27/27 - 1s - loss: 0.2563 - val_loss: 0.2526\nEpoch 34/100\n27/27 - 1s - loss: 0.2545 - val_loss: 0.2530\nEpoch 35/100\n27/27 - 1s - loss: 0.2539 - val_loss: 0.2514\nEpoch 36/100\n27/27 - 1s - loss: 0.2534 - val_loss: 0.2503\nEpoch 37/100\n27/27 - 1s - loss: 0.2509 - val_loss: 0.2474\nEpoch 38/100\n27/27 - 1s - loss: 0.2494 - val_loss: 0.2465\nEpoch 39/100\n27/27 - 1s - loss: 0.2472 - val_loss: 0.2474\nEpoch 40/100\n27/27 - 1s - loss: 0.2461 - val_loss: 0.2466\nEpoch 41/100\n27/27 - 1s - loss: 0.2465 - val_loss: 0.2470\nEpoch 42/100\n27/27 - 1s - loss: 0.2441 - val_loss: 0.2457\nEpoch 43/100\n27/27 - 1s - loss: 0.2423 - val_loss: 0.2425\nEpoch 44/100\n27/27 - 1s - loss: 0.2412 - val_loss: 0.2473\nEpoch 45/100\n27/27 - 1s - loss: 0.2411 - val_loss: 0.2429\nEpoch 46/100\n27/27 - 1s - loss: 0.2406 - val_loss: 0.2417\nEpoch 47/100\n27/27 - 1s - loss: 0.2396 - val_loss: 0.2398\nEpoch 48/100\n27/27 - 1s - loss: 0.2382 - val_loss: 0.2440\nEpoch 49/100\n27/27 - 1s - loss: 0.2365 - val_loss: 0.2406\nEpoch 50/100\n27/27 - 1s - loss: 0.2359 - val_loss: 0.2405\nEpoch 51/100\n27/27 - 1s - loss: 0.2350 - val_loss: 0.2403\nEpoch 52/100\n27/27 - 1s - loss: 0.2345 - val_loss: 0.2391\nEpoch 53/100\n27/27 - 1s - loss: 0.2326 - val_loss: 0.2402\nEpoch 54/100\n27/27 - 1s - loss: 0.2320 - val_loss: 0.2381\nEpoch 55/100\n27/27 - 1s - loss: 0.2318 - val_loss: 0.2376\nEpoch 56/100\n27/27 - 1s - loss: 0.2306 - val_loss: 0.2377\nEpoch 57/100\n27/27 - 1s - loss: 0.2293 - val_loss: 0.2380\nEpoch 58/100\n27/27 - 1s - loss: 0.2292 - val_loss: 0.2353\nEpoch 59/100\n27/27 - 1s - loss: 0.2285 - val_loss: 0.2365\nEpoch 60/100\n27/27 - 1s - loss: 0.2278 - val_loss: 0.2352\nEpoch 61/100\n27/27 - 1s - loss: 0.2257 - val_loss: 0.2351\nEpoch 62/100\n27/27 - 1s - loss: 0.2262 - val_loss: 0.2361\nEpoch 63/100\n27/27 - 1s - loss: 0.2246 - val_loss: 0.2353\nEpoch 64/100\n27/27 - 1s - loss: 0.2240 - val_loss: 0.2343\nEpoch 65/100\n27/27 - 1s - loss: 0.2233 - val_loss: 0.2346\nEpoch 66/100\n27/27 - 1s - loss: 0.2223 - val_loss: 0.2353\nEpoch 67/100\n27/27 - 1s - loss: 0.2218 - val_loss: 0.2367\nEpoch 68/100\n27/27 - 1s - loss: 0.2221 - val_loss: 0.2359\nEpoch 69/100\n27/27 - 1s - loss: 0.2213 - val_loss: 0.2341\nEpoch 70/100\n27/27 - 1s - loss: 0.2204 - val_loss: 0.2317\nEpoch 71/100\n27/27 - 1s - loss: 0.2193 - val_loss: 0.2330\nEpoch 72/100\n27/27 - 1s - loss: 0.2189 - val_loss: 0.2316\nEpoch 73/100\n27/27 - 1s - loss: 0.2175 - val_loss: 0.2310\nEpoch 74/100\n27/27 - 1s - loss: 0.2167 - val_loss: 0.2312\nEpoch 75/100\n27/27 - 1s - loss: 0.2168 - val_loss: 0.2318\nEpoch 76/100\n27/27 - 1s - loss: 0.2160 - val_loss: 0.2302\nEpoch 77/100\n27/27 - 1s - loss: 0.2153 - val_loss: 0.2315\nEpoch 78/100\n27/27 - 1s - loss: 0.2156 - val_loss: 0.2301\nEpoch 79/100\n27/27 - 1s - loss: 0.2145 - val_loss: 0.2310\nEpoch 80/100\n27/27 - 1s - loss: 0.2141 - val_loss: 0.2312\nEpoch 81/100\n27/27 - 1s - loss: 0.2131 - val_loss: 0.2315\nEpoch 82/100\n27/27 - 1s - loss: 0.2129 - val_loss: 0.2302\nEpoch 83/100\n27/27 - 1s - loss: 0.2114 - val_loss: 0.2302\nEpoch 84/100\n27/27 - 1s - loss: 0.2109 - val_loss: 0.2317\nEpoch 85/100\n27/27 - 1s - loss: 0.2105 - val_loss: 0.2303\nEpoch 86/100\n27/27 - 1s - loss: 0.2104 - val_loss: 0.2308\nEpoch 87/100\n27/27 - 1s - loss: 0.2100 - val_loss: 0.2305\nEpoch 88/100\n27/27 - 1s - loss: 0.2091 - val_loss: 0.2284\nEpoch 89/100\n27/27 - 1s - loss: 0.2087 - val_loss: 0.2284\nEpoch 90/100\n27/27 - 1s - loss: 0.2079 - val_loss: 0.2286\nEpoch 91/100\n27/27 - 1s - loss: 0.2074 - val_loss: 0.2280\nEpoch 92/100\n27/27 - 1s - loss: 0.2076 - val_loss: 0.2280\nEpoch 93/100\n27/27 - 1s - loss: 0.2063 - val_loss: 0.2273\nEpoch 94/100\n27/27 - 1s - loss: 0.2062 - val_loss: 0.2273\nEpoch 95/100\n27/27 - 1s - loss: 0.2055 - val_loss: 0.2291\nEpoch 96/100\n27/27 - 1s - loss: 0.2058 - val_loss: 0.2288\nEpoch 97/100\n27/27 - 1s - loss: 0.2054 - val_loss: 0.2274\nEpoch 98/100\n27/27 - 1s - loss: 0.2041 - val_loss: 0.2282\nEpoch 99/100\n27/27 - 1s - loss: 0.2044 - val_loss: 0.2272\nEpoch 100/100\n27/27 - 1s - loss: 0.2037 - val_loss: 0.2267\nMin training loss=0.2037142813205719, min validation loss=0.22665159404277802\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"### 2. LSTM"},{"metadata":{"trusted":true},"cell_type":"code","source":"lstm = build_model(gru=0)\nsv_lstm = tf.keras.callbacks.ModelCheckpoint('model_lstm.h5')\n\nhistory_lstm = lstm.fit(\n    train_inputs, train_labels, \n    validation_data=(val_inputs,val_labels),\n    batch_size=64,\n    epochs=100,\n    callbacks=[lr_callback,sv_lstm],\n    verbose = 2\n)\n\nprint(f\"Min training loss={min(history_lstm.history['loss'])}, min validation loss={min(history_lstm.history['val_loss'])}\")","execution_count":18,"outputs":[{"output_type":"stream","text":"Epoch 1/100\n27/27 - 3s - loss: 0.4911 - val_loss: 0.4415\nEpoch 2/100\n27/27 - 1s - loss: 0.4184 - val_loss: 0.4057\nEpoch 3/100\n27/27 - 1s - loss: 0.3892 - val_loss: 0.3872\nEpoch 4/100\n27/27 - 1s - loss: 0.3767 - val_loss: 0.3750\nEpoch 5/100\n27/27 - 1s - loss: 0.3649 - val_loss: 0.3610\nEpoch 6/100\n27/27 - 1s - loss: 0.3541 - val_loss: 0.3530\nEpoch 7/100\n27/27 - 1s - loss: 0.3470 - val_loss: 0.3469\nEpoch 8/100\n27/27 - 2s - loss: 0.3409 - val_loss: 0.3374\nEpoch 9/100\n27/27 - 2s - loss: 0.3342 - val_loss: 0.3358\nEpoch 10/100\n27/27 - 1s - loss: 0.3294 - val_loss: 0.3282\nEpoch 11/100\n27/27 - 1s - loss: 0.3249 - val_loss: 0.3209\nEpoch 12/100\n27/27 - 1s - loss: 0.3212 - val_loss: 0.3181\nEpoch 13/100\n27/27 - 1s - loss: 0.3163 - val_loss: 0.3127\nEpoch 14/100\n27/27 - 1s - loss: 0.3114 - val_loss: 0.3072\nEpoch 15/100\n27/27 - 2s - loss: 0.3078 - val_loss: 0.3058\nEpoch 16/100\n27/27 - 1s - loss: 0.3035 - val_loss: 0.3006\nEpoch 17/100\n27/27 - 1s - loss: 0.2995 - val_loss: 0.2957\nEpoch 18/100\n27/27 - 1s - loss: 0.2963 - val_loss: 0.2937\nEpoch 19/100\n27/27 - 1s - loss: 0.2930 - val_loss: 0.2958\nEpoch 20/100\n27/27 - 1s - loss: 0.2900 - val_loss: 0.2865\nEpoch 21/100\n27/27 - 2s - loss: 0.2870 - val_loss: 0.2819\nEpoch 22/100\n27/27 - 2s - loss: 0.2823 - val_loss: 0.2821\nEpoch 23/100\n27/27 - 2s - loss: 0.2779 - val_loss: 0.2753\nEpoch 24/100\n27/27 - 1s - loss: 0.2746 - val_loss: 0.2677\nEpoch 25/100\n27/27 - 1s - loss: 0.2717 - val_loss: 0.2677\nEpoch 26/100\n27/27 - 1s - loss: 0.2680 - val_loss: 0.2633\nEpoch 27/100\n27/27 - 2s - loss: 0.2646 - val_loss: 0.2594\nEpoch 28/100\n27/27 - 1s - loss: 0.2621 - val_loss: 0.2573\nEpoch 29/100\n27/27 - 2s - loss: 0.2594 - val_loss: 0.2566\nEpoch 30/100\n27/27 - 1s - loss: 0.2571 - val_loss: 0.2550\nEpoch 31/100\n27/27 - 1s - loss: 0.2543 - val_loss: 0.2522\nEpoch 32/100\n27/27 - 1s - loss: 0.2525 - val_loss: 0.2516\nEpoch 33/100\n27/27 - 1s - loss: 0.2499 - val_loss: 0.2510\nEpoch 34/100\n27/27 - 1s - loss: 0.2481 - val_loss: 0.2477\nEpoch 35/100\n27/27 - 1s - loss: 0.2458 - val_loss: 0.2462\nEpoch 36/100\n27/27 - 2s - loss: 0.2444 - val_loss: 0.2489\nEpoch 37/100\n27/27 - 1s - loss: 0.2436 - val_loss: 0.2447\nEpoch 38/100\n27/27 - 1s - loss: 0.2411 - val_loss: 0.2453\nEpoch 39/100\n27/27 - 1s - loss: 0.2398 - val_loss: 0.2464\nEpoch 40/100\n27/27 - 1s - loss: 0.2375 - val_loss: 0.2450\nEpoch 41/100\n27/27 - 1s - loss: 0.2361 - val_loss: 0.2449\nEpoch 42/100\n27/27 - 1s - loss: 0.2353 - val_loss: 0.2441\nEpoch 43/100\n27/27 - 2s - loss: 0.2330 - val_loss: 0.2420\nEpoch 44/100\n27/27 - 1s - loss: 0.2322 - val_loss: 0.2401\nEpoch 45/100\n27/27 - 1s - loss: 0.2305 - val_loss: 0.2397\nEpoch 46/100\n27/27 - 2s - loss: 0.2299 - val_loss: 0.2389\nEpoch 47/100\n27/27 - 2s - loss: 0.2281 - val_loss: 0.2389\nEpoch 48/100\n27/27 - 2s - loss: 0.2267 - val_loss: 0.2378\nEpoch 49/100\n27/27 - 2s - loss: 0.2251 - val_loss: 0.2380\nEpoch 50/100\n27/27 - 2s - loss: 0.2235 - val_loss: 0.2365\nEpoch 51/100\n27/27 - 1s - loss: 0.2230 - val_loss: 0.2368\nEpoch 52/100\n27/27 - 2s - loss: 0.2220 - val_loss: 0.2381\nEpoch 53/100\n27/27 - 1s - loss: 0.2209 - val_loss: 0.2352\nEpoch 54/100\n27/27 - 1s - loss: 0.2206 - val_loss: 0.2353\nEpoch 55/100\n27/27 - 1s - loss: 0.2195 - val_loss: 0.2346\nEpoch 56/100\n27/27 - 1s - loss: 0.2181 - val_loss: 0.2364\nEpoch 57/100\n27/27 - 2s - loss: 0.2172 - val_loss: 0.2357\nEpoch 58/100\n27/27 - 1s - loss: 0.2160 - val_loss: 0.2373\nEpoch 59/100\n27/27 - 2s - loss: 0.2153 - val_loss: 0.2336\nEpoch 60/100\n27/27 - 1s - loss: 0.2141 - val_loss: 0.2342\nEpoch 61/100\n27/27 - 1s - loss: 0.2128 - val_loss: 0.2344\nEpoch 62/100\n27/27 - 1s - loss: 0.2135 - val_loss: 0.2343\nEpoch 63/100\n27/27 - 2s - loss: 0.2116 - val_loss: 0.2338\nEpoch 64/100\n27/27 - 2s - loss: 0.2101 - val_loss: 0.2331\nEpoch 65/100\n27/27 - 1s - loss: 0.2090 - val_loss: 0.2320\nEpoch 66/100\n27/27 - 2s - loss: 0.2079 - val_loss: 0.2325\nEpoch 67/100\n27/27 - 2s - loss: 0.2070 - val_loss: 0.2325\nEpoch 68/100\n27/27 - 1s - loss: 0.2069 - val_loss: 0.2320\nEpoch 69/100\n27/27 - 1s - loss: 0.2063 - val_loss: 0.2304\nEpoch 70/100\n27/27 - 2s - loss: 0.2051 - val_loss: 0.2319\nEpoch 71/100\n27/27 - 2s - loss: 0.2044 - val_loss: 0.2342\nEpoch 72/100\n27/27 - 1s - loss: 0.2034 - val_loss: 0.2304\nEpoch 73/100\n27/27 - 1s - loss: 0.2024 - val_loss: 0.2312\nEpoch 74/100\n27/27 - 1s - loss: 0.2023 - val_loss: 0.2314\nEpoch 75/100\n27/27 - 1s - loss: 0.2012 - val_loss: 0.2313\nEpoch 76/100\n27/27 - 1s - loss: 0.2011 - val_loss: 0.2294\nEpoch 77/100\n27/27 - 1s - loss: 0.2003 - val_loss: 0.2294\nEpoch 78/100\n27/27 - 2s - loss: 0.1999 - val_loss: 0.2289\nEpoch 79/100\n27/27 - 1s - loss: 0.1991 - val_loss: 0.2313\nEpoch 80/100\n27/27 - 1s - loss: 0.1979 - val_loss: 0.2298\nEpoch 81/100\n27/27 - 1s - loss: 0.1971 - val_loss: 0.2304\nEpoch 82/100\n27/27 - 2s - loss: 0.1963 - val_loss: 0.2300\nEpoch 83/100\n27/27 - 1s - loss: 0.1963 - val_loss: 0.2299\nEpoch 84/100\n27/27 - 2s - loss: 0.1953 - val_loss: 0.2309\nEpoch 85/100\n27/27 - 2s - loss: 0.1947 - val_loss: 0.2291\nEpoch 86/100\n27/27 - 2s - loss: 0.1943 - val_loss: 0.2307\nEpoch 87/100\n27/27 - 2s - loss: 0.1939 - val_loss: 0.2299\nEpoch 88/100\n27/27 - 2s - loss: 0.1928 - val_loss: 0.2309\nEpoch 89/100\n27/27 - 2s - loss: 0.1909 - val_loss: 0.2282\nEpoch 90/100\n27/27 - 2s - loss: 0.1896 - val_loss: 0.2280\nEpoch 91/100\n27/27 - 1s - loss: 0.1890 - val_loss: 0.2278\nEpoch 92/100\n27/27 - 2s - loss: 0.1888 - val_loss: 0.2278\nEpoch 93/100\n27/27 - 1s - loss: 0.1882 - val_loss: 0.2281\nEpoch 94/100\n27/27 - 2s - loss: 0.1883 - val_loss: 0.2277\nEpoch 95/100\n27/27 - 1s - loss: 0.1882 - val_loss: 0.2275\nEpoch 96/100\n27/27 - 1s - loss: 0.1882 - val_loss: 0.2277\nEpoch 97/100\n27/27 - 1s - loss: 0.1879 - val_loss: 0.2274\nEpoch 98/100\n27/27 - 2s - loss: 0.1877 - val_loss: 0.2273\nEpoch 99/100\n27/27 - 2s - loss: 0.1876 - val_loss: 0.2278\nEpoch 100/100\n27/27 - 1s - loss: 0.1875 - val_loss: 0.2273\nMin training loss=0.18750448524951935, min validation loss=0.22727070748806\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"# 3. Hyb1"},{"metadata":{"trusted":true},"cell_type":"code","source":"lstm = build_model(gru=3)\nsv_lstm = tf.keras.callbacks.ModelCheckpoint('model_hyb1.h5')\n\nhistory_lstm = lstm.fit(\n    train_inputs, train_labels, \n    validation_data=(val_inputs,val_labels),\n    batch_size=64,\n    epochs=100,\n    callbacks=[lr_callback,sv_lstm],\n    verbose = 2\n)\n\nprint(f\"Min training loss={min(history_lstm.history['loss'])}, min validation loss={min(history_lstm.history['val_loss'])}\")","execution_count":19,"outputs":[{"output_type":"stream","text":"Epoch 1/100\n27/27 - 3s - loss: 0.4845 - val_loss: 0.4275\nEpoch 2/100\n27/27 - 1s - loss: 0.4052 - val_loss: 0.3995\nEpoch 3/100\n27/27 - 1s - loss: 0.3861 - val_loss: 0.3857\nEpoch 4/100\n27/27 - 1s - loss: 0.3746 - val_loss: 0.3783\nEpoch 5/100\n27/27 - 1s - loss: 0.3633 - val_loss: 0.3581\nEpoch 6/100\n27/27 - 1s - loss: 0.3487 - val_loss: 0.3454\nEpoch 7/100\n27/27 - 1s - loss: 0.3403 - val_loss: 0.3384\nEpoch 8/100\n27/27 - 1s - loss: 0.3322 - val_loss: 0.3305\nEpoch 9/100\n27/27 - 1s - loss: 0.3247 - val_loss: 0.3217\nEpoch 10/100\n27/27 - 1s - loss: 0.3196 - val_loss: 0.3184\nEpoch 11/100\n27/27 - 1s - loss: 0.3132 - val_loss: 0.3089\nEpoch 12/100\n27/27 - 1s - loss: 0.3083 - val_loss: 0.3067\nEpoch 13/100\n27/27 - 1s - loss: 0.3037 - val_loss: 0.3010\nEpoch 14/100\n27/27 - 2s - loss: 0.2989 - val_loss: 0.2968\nEpoch 15/100\n27/27 - 1s - loss: 0.2957 - val_loss: 0.2964\nEpoch 16/100\n27/27 - 1s - loss: 0.2924 - val_loss: 0.2911\nEpoch 17/100\n27/27 - 2s - loss: 0.2876 - val_loss: 0.2845\nEpoch 18/100\n27/27 - 1s - loss: 0.2827 - val_loss: 0.2800\nEpoch 19/100\n27/27 - 1s - loss: 0.2809 - val_loss: 0.2791\nEpoch 20/100\n27/27 - 1s - loss: 0.2750 - val_loss: 0.2730\nEpoch 21/100\n27/27 - 1s - loss: 0.2724 - val_loss: 0.2686\nEpoch 22/100\n27/27 - 1s - loss: 0.2678 - val_loss: 0.2639\nEpoch 23/100\n27/27 - 1s - loss: 0.2651 - val_loss: 0.2627\nEpoch 24/100\n27/27 - 1s - loss: 0.2608 - val_loss: 0.2599\nEpoch 25/100\n27/27 - 1s - loss: 0.2587 - val_loss: 0.2554\nEpoch 26/100\n27/27 - 1s - loss: 0.2555 - val_loss: 0.2555\nEpoch 27/100\n27/27 - 1s - loss: 0.2533 - val_loss: 0.2535\nEpoch 28/100\n27/27 - 1s - loss: 0.2514 - val_loss: 0.2513\nEpoch 29/100\n27/27 - 1s - loss: 0.2499 - val_loss: 0.2488\nEpoch 30/100\n27/27 - 1s - loss: 0.2473 - val_loss: 0.2485\nEpoch 31/100\n27/27 - 1s - loss: 0.2458 - val_loss: 0.2486\nEpoch 32/100\n27/27 - 1s - loss: 0.2443 - val_loss: 0.2484\nEpoch 33/100\n27/27 - 1s - loss: 0.2420 - val_loss: 0.2448\nEpoch 34/100\n27/27 - 1s - loss: 0.2399 - val_loss: 0.2443\nEpoch 35/100\n27/27 - 1s - loss: 0.2379 - val_loss: 0.2430\nEpoch 36/100\n27/27 - 1s - loss: 0.2369 - val_loss: 0.2405\nEpoch 37/100\n27/27 - 2s - loss: 0.2355 - val_loss: 0.2422\nEpoch 38/100\n27/27 - 1s - loss: 0.2346 - val_loss: 0.2426\nEpoch 39/100\n27/27 - 1s - loss: 0.2331 - val_loss: 0.2401\nEpoch 40/100\n27/27 - 1s - loss: 0.2319 - val_loss: 0.2382\nEpoch 41/100\n27/27 - 2s - loss: 0.2313 - val_loss: 0.2424\nEpoch 42/100\n27/27 - 1s - loss: 0.2293 - val_loss: 0.2374\nEpoch 43/100\n27/27 - 1s - loss: 0.2280 - val_loss: 0.2381\nEpoch 44/100\n27/27 - 1s - loss: 0.2269 - val_loss: 0.2389\nEpoch 45/100\n27/27 - 1s - loss: 0.2256 - val_loss: 0.2353\nEpoch 46/100\n27/27 - 1s - loss: 0.2241 - val_loss: 0.2354\nEpoch 47/100\n27/27 - 1s - loss: 0.2230 - val_loss: 0.2362\nEpoch 48/100\n27/27 - 1s - loss: 0.2230 - val_loss: 0.2362\nEpoch 49/100\n27/27 - 1s - loss: 0.2215 - val_loss: 0.2339\nEpoch 50/100\n27/27 - 1s - loss: 0.2209 - val_loss: 0.2349\nEpoch 51/100\n27/27 - 1s - loss: 0.2193 - val_loss: 0.2336\nEpoch 52/100\n27/27 - 1s - loss: 0.2186 - val_loss: 0.2336\nEpoch 53/100\n27/27 - 1s - loss: 0.2171 - val_loss: 0.2329\nEpoch 54/100\n27/27 - 1s - loss: 0.2170 - val_loss: 0.2330\nEpoch 55/100\n27/27 - 1s - loss: 0.2155 - val_loss: 0.2317\nEpoch 56/100\n27/27 - 1s - loss: 0.2141 - val_loss: 0.2315\nEpoch 57/100\n27/27 - 2s - loss: 0.2134 - val_loss: 0.2320\nEpoch 58/100\n27/27 - 2s - loss: 0.2132 - val_loss: 0.2332\nEpoch 59/100\n27/27 - 1s - loss: 0.2126 - val_loss: 0.2313\nEpoch 60/100\n27/27 - 1s - loss: 0.2109 - val_loss: 0.2321\nEpoch 61/100\n27/27 - 1s - loss: 0.2102 - val_loss: 0.2293\nEpoch 62/100\n27/27 - 1s - loss: 0.2096 - val_loss: 0.2298\nEpoch 63/100\n27/27 - 1s - loss: 0.2087 - val_loss: 0.2306\nEpoch 64/100\n27/27 - 1s - loss: 0.2089 - val_loss: 0.2313\nEpoch 65/100\n27/27 - 1s - loss: 0.2075 - val_loss: 0.2310\nEpoch 66/100\n27/27 - 1s - loss: 0.2070 - val_loss: 0.2302\nEpoch 67/100\n27/27 - 1s - loss: 0.2057 - val_loss: 0.2306\nEpoch 68/100\n27/27 - 1s - loss: 0.2052 - val_loss: 0.2291\nEpoch 69/100\n27/27 - 1s - loss: 0.2043 - val_loss: 0.2295\nEpoch 70/100\n27/27 - 1s - loss: 0.2042 - val_loss: 0.2300\nEpoch 71/100\n27/27 - 1s - loss: 0.2041 - val_loss: 0.2296\nEpoch 72/100\n27/27 - 1s - loss: 0.2027 - val_loss: 0.2290\nEpoch 73/100\n27/27 - 1s - loss: 0.2024 - val_loss: 0.2308\nEpoch 74/100\n27/27 - 1s - loss: 0.2019 - val_loss: 0.2284\nEpoch 75/100\n27/27 - 1s - loss: 0.2007 - val_loss: 0.2289\nEpoch 76/100\n27/27 - 1s - loss: 0.2001 - val_loss: 0.2302\nEpoch 77/100\n27/27 - 1s - loss: 0.1999 - val_loss: 0.2287\nEpoch 78/100\n27/27 - 1s - loss: 0.1995 - val_loss: 0.2303\nEpoch 79/100\n27/27 - 1s - loss: 0.1984 - val_loss: 0.2295\nEpoch 80/100\n27/27 - 1s - loss: 0.1981 - val_loss: 0.2274\nEpoch 81/100\n27/27 - 1s - loss: 0.1969 - val_loss: 0.2284\nEpoch 82/100\n27/27 - 1s - loss: 0.1964 - val_loss: 0.2293\nEpoch 83/100\n27/27 - 1s - loss: 0.1964 - val_loss: 0.2289\nEpoch 84/100\n27/27 - 1s - loss: 0.1959 - val_loss: 0.2285\nEpoch 85/100\n27/27 - 1s - loss: 0.1955 - val_loss: 0.2267\nEpoch 86/100\n27/27 - 1s - loss: 0.1952 - val_loss: 0.2282\nEpoch 87/100\n27/27 - 1s - loss: 0.1943 - val_loss: 0.2253\nEpoch 88/100\n27/27 - 1s - loss: 0.1944 - val_loss: 0.2265\nEpoch 89/100\n27/27 - 1s - loss: 0.1931 - val_loss: 0.2276\nEpoch 90/100\n27/27 - 1s - loss: 0.1924 - val_loss: 0.2260\nEpoch 91/100\n27/27 - 1s - loss: 0.1919 - val_loss: 0.2259\nEpoch 92/100\n27/27 - 1s - loss: 0.1919 - val_loss: 0.2268\nEpoch 93/100\n27/27 - 1s - loss: 0.1916 - val_loss: 0.2277\nEpoch 94/100\n27/27 - 1s - loss: 0.1911 - val_loss: 0.2254\nEpoch 95/100\n27/27 - 1s - loss: 0.1907 - val_loss: 0.2266\nEpoch 96/100\n27/27 - 1s - loss: 0.1901 - val_loss: 0.2274\nEpoch 97/100\n27/27 - 2s - loss: 0.1894 - val_loss: 0.2259\nEpoch 98/100\n27/27 - 1s - loss: 0.1875 - val_loss: 0.2256\nEpoch 99/100\n27/27 - 1s - loss: 0.1864 - val_loss: 0.2253\nEpoch 100/100\n27/27 - 1s - loss: 0.1864 - val_loss: 0.2250\nMin training loss=0.18640737235546112, min validation loss=0.22495855391025543\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"# 4. Hyb2"},{"metadata":{"trusted":true},"cell_type":"code","source":"lstm = build_model(gru=4)\nsv_lstm = tf.keras.callbacks.ModelCheckpoint('model_hyb2.h5')\n\nhistory_lstm = lstm.fit(\n    train_inputs, train_labels, \n    validation_data=(val_inputs,val_labels),\n    batch_size=64,\n    epochs=100,\n    callbacks=[lr_callback,sv_lstm],\n    verbose = 2\n)\n\nprint(f\"Min training loss={min(history_lstm.history['loss'])}, min validation loss={min(history_lstm.history['val_loss'])}\")","execution_count":20,"outputs":[{"output_type":"stream","text":"Epoch 1/100\n27/27 - 3s - loss: 0.4759 - val_loss: 0.4198\nEpoch 2/100\n27/27 - 1s - loss: 0.4024 - val_loss: 0.3962\nEpoch 3/100\n27/27 - 1s - loss: 0.3856 - val_loss: 0.3822\nEpoch 4/100\n27/27 - 1s - loss: 0.3712 - val_loss: 0.3687\nEpoch 5/100\n27/27 - 1s - loss: 0.3595 - val_loss: 0.3612\nEpoch 6/100\n27/27 - 1s - loss: 0.3535 - val_loss: 0.3522\nEpoch 7/100\n27/27 - 1s - loss: 0.3469 - val_loss: 0.3498\nEpoch 8/100\n27/27 - 1s - loss: 0.3429 - val_loss: 0.3439\nEpoch 9/100\n27/27 - 1s - loss: 0.3370 - val_loss: 0.3350\nEpoch 10/100\n27/27 - 1s - loss: 0.3328 - val_loss: 0.3339\nEpoch 11/100\n27/27 - 1s - loss: 0.3278 - val_loss: 0.3251\nEpoch 12/100\n27/27 - 1s - loss: 0.3229 - val_loss: 0.3215\nEpoch 13/100\n27/27 - 1s - loss: 0.3192 - val_loss: 0.3180\nEpoch 14/100\n27/27 - 1s - loss: 0.3149 - val_loss: 0.3139\nEpoch 15/100\n27/27 - 1s - loss: 0.3102 - val_loss: 0.3091\nEpoch 16/100\n27/27 - 1s - loss: 0.3070 - val_loss: 0.3032\nEpoch 17/100\n27/27 - 1s - loss: 0.3029 - val_loss: 0.2989\nEpoch 18/100\n27/27 - 1s - loss: 0.2986 - val_loss: 0.2954\nEpoch 19/100\n27/27 - 1s - loss: 0.2945 - val_loss: 0.2909\nEpoch 20/100\n27/27 - 1s - loss: 0.2909 - val_loss: 0.2843\nEpoch 21/100\n27/27 - 1s - loss: 0.2861 - val_loss: 0.2805\nEpoch 22/100\n27/27 - 1s - loss: 0.2822 - val_loss: 0.2739\nEpoch 23/100\n27/27 - 1s - loss: 0.2779 - val_loss: 0.2739\nEpoch 24/100\n27/27 - 1s - loss: 0.2745 - val_loss: 0.2670\nEpoch 25/100\n27/27 - 1s - loss: 0.2716 - val_loss: 0.2656\nEpoch 26/100\n27/27 - 1s - loss: 0.2690 - val_loss: 0.2641\nEpoch 27/100\n27/27 - 1s - loss: 0.2668 - val_loss: 0.2579\nEpoch 28/100\n27/27 - 1s - loss: 0.2644 - val_loss: 0.2574\nEpoch 29/100\n27/27 - 1s - loss: 0.2612 - val_loss: 0.2546\nEpoch 30/100\n27/27 - 1s - loss: 0.2597 - val_loss: 0.2565\nEpoch 31/100\n27/27 - 1s - loss: 0.2575 - val_loss: 0.2510\nEpoch 32/100\n27/27 - 1s - loss: 0.2558 - val_loss: 0.2547\nEpoch 33/100\n27/27 - 1s - loss: 0.2545 - val_loss: 0.2514\nEpoch 34/100\n27/27 - 1s - loss: 0.2533 - val_loss: 0.2485\nEpoch 35/100\n27/27 - 1s - loss: 0.2510 - val_loss: 0.2474\nEpoch 36/100\n27/27 - 1s - loss: 0.2500 - val_loss: 0.2472\nEpoch 37/100\n27/27 - 1s - loss: 0.2486 - val_loss: 0.2478\nEpoch 38/100\n27/27 - 1s - loss: 0.2470 - val_loss: 0.2457\nEpoch 39/100\n27/27 - 1s - loss: 0.2459 - val_loss: 0.2473\nEpoch 40/100\n27/27 - 1s - loss: 0.2449 - val_loss: 0.2436\nEpoch 41/100\n27/27 - 1s - loss: 0.2435 - val_loss: 0.2425\nEpoch 42/100\n27/27 - 1s - loss: 0.2416 - val_loss: 0.2459\nEpoch 43/100\n27/27 - 1s - loss: 0.2412 - val_loss: 0.2421\nEpoch 44/100\n27/27 - 1s - loss: 0.2396 - val_loss: 0.2414\nEpoch 45/100\n27/27 - 1s - loss: 0.2390 - val_loss: 0.2429\nEpoch 46/100\n27/27 - 1s - loss: 0.2385 - val_loss: 0.2393\nEpoch 47/100\n27/27 - 1s - loss: 0.2368 - val_loss: 0.2384\nEpoch 48/100\n27/27 - 1s - loss: 0.2350 - val_loss: 0.2399\nEpoch 49/100\n27/27 - 1s - loss: 0.2342 - val_loss: 0.2441\nEpoch 50/100\n27/27 - 1s - loss: 0.2338 - val_loss: 0.2378\nEpoch 51/100\n27/27 - 1s - loss: 0.2315 - val_loss: 0.2359\nEpoch 52/100\n27/27 - 1s - loss: 0.2318 - val_loss: 0.2373\nEpoch 53/100\n27/27 - 1s - loss: 0.2299 - val_loss: 0.2369\nEpoch 54/100\n27/27 - 1s - loss: 0.2290 - val_loss: 0.2356\nEpoch 55/100\n27/27 - 1s - loss: 0.2285 - val_loss: 0.2358\nEpoch 56/100\n27/27 - 1s - loss: 0.2278 - val_loss: 0.2377\nEpoch 57/100\n27/27 - 1s - loss: 0.2271 - val_loss: 0.2369\nEpoch 58/100\n27/27 - 1s - loss: 0.2255 - val_loss: 0.2323\nEpoch 59/100\n27/27 - 1s - loss: 0.2253 - val_loss: 0.2356\nEpoch 60/100\n27/27 - 1s - loss: 0.2241 - val_loss: 0.2336\nEpoch 61/100\n27/27 - 1s - loss: 0.2227 - val_loss: 0.2312\nEpoch 62/100\n27/27 - 1s - loss: 0.2227 - val_loss: 0.2326\nEpoch 63/100\n27/27 - 1s - loss: 0.2218 - val_loss: 0.2333\nEpoch 64/100\n27/27 - 2s - loss: 0.2215 - val_loss: 0.2317\nEpoch 65/100\n27/27 - 1s - loss: 0.2202 - val_loss: 0.2305\nEpoch 66/100\n27/27 - 1s - loss: 0.2193 - val_loss: 0.2336\nEpoch 67/100\n27/27 - 1s - loss: 0.2189 - val_loss: 0.2321\nEpoch 68/100\n27/27 - 1s - loss: 0.2174 - val_loss: 0.2298\nEpoch 69/100\n27/27 - 1s - loss: 0.2168 - val_loss: 0.2327\nEpoch 70/100\n27/27 - 1s - loss: 0.2165 - val_loss: 0.2290\nEpoch 71/100\n27/27 - 1s - loss: 0.2154 - val_loss: 0.2309\nEpoch 72/100\n27/27 - 1s - loss: 0.2150 - val_loss: 0.2298\nEpoch 73/100\n27/27 - 1s - loss: 0.2141 - val_loss: 0.2288\nEpoch 74/100\n27/27 - 1s - loss: 0.2135 - val_loss: 0.2293\nEpoch 75/100\n27/27 - 1s - loss: 0.2128 - val_loss: 0.2285\nEpoch 76/100\n27/27 - 1s - loss: 0.2128 - val_loss: 0.2277\nEpoch 77/100\n27/27 - 1s - loss: 0.2119 - val_loss: 0.2278\nEpoch 78/100\n27/27 - 1s - loss: 0.2112 - val_loss: 0.2299\nEpoch 79/100\n27/27 - 1s - loss: 0.2104 - val_loss: 0.2279\nEpoch 80/100\n27/27 - 1s - loss: 0.2099 - val_loss: 0.2293\nEpoch 81/100\n27/27 - 1s - loss: 0.2093 - val_loss: 0.2270\nEpoch 82/100\n27/27 - 1s - loss: 0.2081 - val_loss: 0.2305\nEpoch 83/100\n27/27 - 1s - loss: 0.2083 - val_loss: 0.2271\nEpoch 84/100\n27/27 - 1s - loss: 0.2078 - val_loss: 0.2276\nEpoch 85/100\n27/27 - 1s - loss: 0.2072 - val_loss: 0.2288\nEpoch 86/100\n27/27 - 1s - loss: 0.2063 - val_loss: 0.2279\nEpoch 87/100\n27/27 - 1s - loss: 0.2054 - val_loss: 0.2257\nEpoch 88/100\n27/27 - 1s - loss: 0.2046 - val_loss: 0.2283\nEpoch 89/100\n27/27 - 1s - loss: 0.2039 - val_loss: 0.2263\nEpoch 90/100\n27/27 - 1s - loss: 0.2040 - val_loss: 0.2270\nEpoch 91/100\n27/27 - 1s - loss: 0.2034 - val_loss: 0.2276\nEpoch 92/100\n27/27 - 1s - loss: 0.2025 - val_loss: 0.2307\nEpoch 93/100\n27/27 - 1s - loss: 0.2028 - val_loss: 0.2255\nEpoch 94/100\n27/27 - 1s - loss: 0.2027 - val_loss: 0.2280\nEpoch 95/100\n27/27 - 1s - loss: 0.2018 - val_loss: 0.2262\nEpoch 96/100\n27/27 - 1s - loss: 0.2010 - val_loss: 0.2255\nEpoch 97/100\n27/27 - 1s - loss: 0.2001 - val_loss: 0.2261\nEpoch 98/100\n27/27 - 1s - loss: 0.1999 - val_loss: 0.2269\nEpoch 99/100\n27/27 - 1s - loss: 0.2001 - val_loss: 0.2262\nEpoch 100/100\n27/27 - 1s - loss: 0.1995 - val_loss: 0.2250\nMin training loss=0.199497789144516, min validation loss=0.22498053312301636\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"# 5. hyb3"},{"metadata":{"trusted":true},"cell_type":"code","source":"lstm = build_model(gru=5)\nsv_lstm = tf.keras.callbacks.ModelCheckpoint('model_hyb3.h5')\n\nhistory_lstm = lstm.fit(\n    train_inputs, train_labels, \n    validation_data=(val_inputs,val_labels),\n    batch_size=64,\n    epochs=100,\n    callbacks=[lr_callback,sv_lstm],\n    verbose = 2\n)\n\nprint(f\"Min training loss={min(history_lstm.history['loss'])}, min validation loss={min(history_lstm.history['val_loss'])}\")","execution_count":21,"outputs":[{"output_type":"stream","text":"Epoch 1/100\n27/27 - 1s - loss: 0.4922 - val_loss: 0.4408\nEpoch 2/100\n27/27 - 1s - loss: 0.4085 - val_loss: 0.4044\nEpoch 3/100\n27/27 - 1s - loss: 0.3848 - val_loss: 0.3835\nEpoch 4/100\n27/27 - 1s - loss: 0.3701 - val_loss: 0.3696\nEpoch 5/100\n27/27 - 1s - loss: 0.3577 - val_loss: 0.3607\nEpoch 6/100\n27/27 - 1s - loss: 0.3495 - val_loss: 0.3519\nEpoch 7/100\n27/27 - 1s - loss: 0.3429 - val_loss: 0.3463\nEpoch 8/100\n27/27 - 1s - loss: 0.3390 - val_loss: 0.3425\nEpoch 9/100\n27/27 - 1s - loss: 0.3348 - val_loss: 0.3374\nEpoch 10/100\n27/27 - 1s - loss: 0.3323 - val_loss: 0.3375\nEpoch 11/100\n27/27 - 1s - loss: 0.3299 - val_loss: 0.3325\nEpoch 12/100\n27/27 - 1s - loss: 0.3253 - val_loss: 0.3299\nEpoch 13/100\n27/27 - 1s - loss: 0.3229 - val_loss: 0.3278\nEpoch 14/100\n27/27 - 1s - loss: 0.3191 - val_loss: 0.3238\nEpoch 15/100\n27/27 - 1s - loss: 0.3155 - val_loss: 0.3182\nEpoch 16/100\n27/27 - 1s - loss: 0.3120 - val_loss: 0.3140\nEpoch 17/100\n27/27 - 1s - loss: 0.3088 - val_loss: 0.3123\nEpoch 18/100\n27/27 - 1s - loss: 0.3056 - val_loss: 0.3082\nEpoch 19/100\n27/27 - 1s - loss: 0.3045 - val_loss: 0.3081\nEpoch 20/100\n27/27 - 1s - loss: 0.3011 - val_loss: 0.3060\nEpoch 21/100\n27/27 - 1s - loss: 0.2998 - val_loss: 0.3026\nEpoch 22/100\n27/27 - 1s - loss: 0.2978 - val_loss: 0.3009\nEpoch 23/100\n27/27 - 1s - loss: 0.2951 - val_loss: 0.2971\nEpoch 24/100\n27/27 - 1s - loss: 0.2926 - val_loss: 0.2959\nEpoch 25/100\n27/27 - 1s - loss: 0.2899 - val_loss: 0.2926\nEpoch 26/100\n27/27 - 1s - loss: 0.2882 - val_loss: 0.2905\nEpoch 27/100\n27/27 - 1s - loss: 0.2860 - val_loss: 0.2893\nEpoch 28/100\n27/27 - 1s - loss: 0.2846 - val_loss: 0.2869\nEpoch 29/100\n27/27 - 1s - loss: 0.2828 - val_loss: 0.2859\nEpoch 30/100\n27/27 - 1s - loss: 0.2829 - val_loss: 0.2837\nEpoch 31/100\n27/27 - 1s - loss: 0.2791 - val_loss: 0.2820\nEpoch 32/100\n27/27 - 1s - loss: 0.2777 - val_loss: 0.2795\nEpoch 33/100\n27/27 - 1s - loss: 0.2754 - val_loss: 0.2766\nEpoch 34/100\n27/27 - 1s - loss: 0.2738 - val_loss: 0.2748\nEpoch 35/100\n27/27 - 1s - loss: 0.2725 - val_loss: 0.2766\nEpoch 36/100\n27/27 - 1s - loss: 0.2714 - val_loss: 0.2746\nEpoch 37/100\n27/27 - 1s - loss: 0.2701 - val_loss: 0.2748\nEpoch 38/100\n27/27 - 1s - loss: 0.2694 - val_loss: 0.2720\nEpoch 39/100\n27/27 - 1s - loss: 0.2674 - val_loss: 0.2699\nEpoch 40/100\n27/27 - 1s - loss: 0.2660 - val_loss: 0.2688\nEpoch 41/100\n27/27 - 1s - loss: 0.2648 - val_loss: 0.2688\nEpoch 42/100\n27/27 - 1s - loss: 0.2637 - val_loss: 0.2679\nEpoch 43/100\n27/27 - 1s - loss: 0.2631 - val_loss: 0.2657\nEpoch 44/100\n27/27 - 1s - loss: 0.2623 - val_loss: 0.2653\nEpoch 45/100\n27/27 - 1s - loss: 0.2613 - val_loss: 0.2642\nEpoch 46/100\n27/27 - 1s - loss: 0.2600 - val_loss: 0.2663\nEpoch 47/100\n27/27 - 1s - loss: 0.2598 - val_loss: 0.2683\nEpoch 48/100\n27/27 - 1s - loss: 0.2597 - val_loss: 0.2634\nEpoch 49/100\n27/27 - 1s - loss: 0.2583 - val_loss: 0.2620\nEpoch 50/100\n27/27 - 1s - loss: 0.2563 - val_loss: 0.2605\nEpoch 51/100\n27/27 - 1s - loss: 0.2563 - val_loss: 0.2610\nEpoch 52/100\n27/27 - 1s - loss: 0.2551 - val_loss: 0.2605\nEpoch 53/100\n27/27 - 1s - loss: 0.2548 - val_loss: 0.2600\nEpoch 54/100\n27/27 - 1s - loss: 0.2537 - val_loss: 0.2595\nEpoch 55/100\n27/27 - 1s - loss: 0.2533 - val_loss: 0.2586\nEpoch 56/100\n27/27 - 1s - loss: 0.2525 - val_loss: 0.2575\nEpoch 57/100\n27/27 - 1s - loss: 0.2511 - val_loss: 0.2567\nEpoch 58/100\n27/27 - 1s - loss: 0.2510 - val_loss: 0.2603\nEpoch 59/100\n27/27 - 1s - loss: 0.2511 - val_loss: 0.2562\nEpoch 60/100\n27/27 - 1s - loss: 0.2501 - val_loss: 0.2563\nEpoch 61/100\n27/27 - 1s - loss: 0.2488 - val_loss: 0.2549\nEpoch 62/100\n27/27 - 1s - loss: 0.2482 - val_loss: 0.2572\nEpoch 63/100\n27/27 - 1s - loss: 0.2482 - val_loss: 0.2551\nEpoch 64/100\n27/27 - 1s - loss: 0.2467 - val_loss: 0.2540\nEpoch 65/100\n27/27 - 1s - loss: 0.2466 - val_loss: 0.2529\nEpoch 66/100\n27/27 - 1s - loss: 0.2466 - val_loss: 0.2538\nEpoch 67/100\n27/27 - 1s - loss: 0.2468 - val_loss: 0.2539\nEpoch 68/100\n27/27 - 1s - loss: 0.2459 - val_loss: 0.2526\nEpoch 69/100\n27/27 - 1s - loss: 0.2447 - val_loss: 0.2521\nEpoch 70/100\n27/27 - 1s - loss: 0.2444 - val_loss: 0.2525\nEpoch 71/100\n27/27 - 1s - loss: 0.2438 - val_loss: 0.2520\nEpoch 72/100\n27/27 - 1s - loss: 0.2438 - val_loss: 0.2509\nEpoch 73/100\n27/27 - 1s - loss: 0.2425 - val_loss: 0.2509\nEpoch 74/100\n27/27 - 1s - loss: 0.2412 - val_loss: 0.2506\nEpoch 75/100\n27/27 - 1s - loss: 0.2411 - val_loss: 0.2502\nEpoch 76/100\n27/27 - 1s - loss: 0.2404 - val_loss: 0.2511\nEpoch 77/100\n27/27 - 1s - loss: 0.2399 - val_loss: 0.2499\nEpoch 78/100\n27/27 - 1s - loss: 0.2399 - val_loss: 0.2497\nEpoch 79/100\n27/27 - 1s - loss: 0.2394 - val_loss: 0.2487\nEpoch 80/100\n27/27 - 1s - loss: 0.2389 - val_loss: 0.2487\nEpoch 81/100\n27/27 - 1s - loss: 0.2382 - val_loss: 0.2486\nEpoch 82/100\n27/27 - 1s - loss: 0.2383 - val_loss: 0.2487\nEpoch 83/100\n27/27 - 1s - loss: 0.2376 - val_loss: 0.2476\nEpoch 84/100\n27/27 - 1s - loss: 0.2369 - val_loss: 0.2479\nEpoch 85/100\n27/27 - 1s - loss: 0.2371 - val_loss: 0.2482\nEpoch 86/100\n27/27 - 1s - loss: 0.2371 - val_loss: 0.2482\nEpoch 87/100\n27/27 - 1s - loss: 0.2362 - val_loss: 0.2474\nEpoch 88/100\n27/27 - 1s - loss: 0.2352 - val_loss: 0.2472\nEpoch 89/100\n27/27 - 1s - loss: 0.2353 - val_loss: 0.2477\nEpoch 90/100\n27/27 - 1s - loss: 0.2342 - val_loss: 0.2469\nEpoch 91/100\n27/27 - 1s - loss: 0.2348 - val_loss: 0.2479\nEpoch 92/100\n27/27 - 1s - loss: 0.2341 - val_loss: 0.2456\nEpoch 93/100\n27/27 - 1s - loss: 0.2329 - val_loss: 0.2459\nEpoch 94/100\n27/27 - 1s - loss: 0.2331 - val_loss: 0.2476\nEpoch 95/100\n27/27 - 1s - loss: 0.2325 - val_loss: 0.2458\nEpoch 96/100\n27/27 - 1s - loss: 0.2322 - val_loss: 0.2466\nEpoch 97/100\n27/27 - 1s - loss: 0.2321 - val_loss: 0.2459\nEpoch 98/100\n27/27 - 1s - loss: 0.2312 - val_loss: 0.2465\nEpoch 99/100\n27/27 - 1s - loss: 0.2312 - val_loss: 0.2467\nEpoch 100/100\n27/27 - 1s - loss: 0.2304 - val_loss: 0.2458\nMin training loss=0.23035426437854767, min validation loss=0.24560028314590454\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"# Model Evaluation"},{"metadata":{},"cell_type":"markdown","source":"# Inference and Submission"},{"metadata":{"trusted":true},"cell_type":"code","source":"public_df = test.query(\"seq_length == 107\").copy()\nprivate_df = test.query(\"seq_length == 130\").copy()\n\npublic_inputs = preprocess_inputs(public_df)\nprivate_inputs = preprocess_inputs(private_df)","execution_count":22,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Predict twice, one for the public leaderboard, the other for the private leaderboard:**"},{"metadata":{"trusted":true},"cell_type":"code","source":"# build all models\ngru_short = build_model(gru=1, seq_len=107, pred_len=107)\ngru_long = build_model(gru=1, seq_len=130, pred_len=130)\nlstm_short = build_model(gru=0, seq_len=107, pred_len=107)\nlstm_long = build_model(gru=0, seq_len=130, pred_len=130)\nhyb1_short = build_model(gru=3, seq_len=107, pred_len=107)\nhyb1_long = build_model(gru=3, seq_len=130, pred_len=130)\nhyb2_short = build_model(gru=4, seq_len=107, pred_len=107)\nhyb2_long = build_model(gru=4, seq_len=130, pred_len=130)\nhyb3_short = build_model(gru=5, seq_len=107, pred_len=107)\nhyb3_long = build_model(gru=5, seq_len=130, pred_len=130)\n\n\n# load pre-trained model weights\ngru_short.load_weights('model_gru.h5')\ngru_long.load_weights('model_gru.h5')\nlstm_short.load_weights('model_lstm.h5')\nlstm_long.load_weights('model_lstm.h5')\nhyb1_short.load_weights('model_hyb1.h5')\nhyb1_long.load_weights('model_hyb1.h5')\nhyb2_short.load_weights('model_hyb2.h5')\nhyb2_long.load_weights('model_hyb2.h5')\nhyb3_short.load_weights('model_hyb3.h5')\nhyb3_long.load_weights('model_hyb3.h5')\n\n# and predict\ngru_public_preds = gru_short.predict(public_inputs)\ngru_private_preds = gru_long.predict(private_inputs)\nlstm_public_preds = lstm_short.predict(public_inputs)\nlstm_private_preds = lstm_long.predict(private_inputs)\nhyb1_public_preds = hyb1_short.predict(public_inputs)\nhyb1_private_preds = hyb1_long.predict(private_inputs)\nhyb2_public_preds = hyb2_short.predict(public_inputs)\nhyb2_private_preds = hyb2_long.predict(private_inputs)\nhyb3_public_preds = hyb3_short.predict(public_inputs)\nhyb3_private_preds = hyb3_long.predict(private_inputs)","execution_count":23,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Now we just need to change the shape of each sample to the long format:**"},{"metadata":{"trusted":true},"cell_type":"code","source":"preds_gru = []\n\nfor df, preds in [(public_df, gru_public_preds), (private_df, gru_private_preds)]:\n    for i, uid in enumerate(df.id):\n        single_pred = preds[i]\n\n        single_df = pd.DataFrame(single_pred, columns=target_cols)\n        single_df['id_seqpos'] = [f'{uid}_{x}' for x in range(single_df.shape[0])]\n\n        preds_gru.append(single_df)\n\npreds_gru_df = pd.concat(preds_gru)\npreds_gru_df.head()","execution_count":24,"outputs":[{"output_type":"execute_result","execution_count":24,"data":{"text/plain":"   reactivity  deg_Mg_pH10  deg_pH10  deg_Mg_50C   deg_50C       id_seqpos\n0    0.813204     0.738167  1.892738    0.613165  0.810794  id_00073f8be_0\n1    2.503969     3.582739  4.504695    3.598233  2.934643  id_00073f8be_1\n2    1.264525     0.555534  0.651592    0.724087  0.663601  id_00073f8be_2\n3    1.115623     0.917757  1.156807    1.523429  1.525713  id_00073f8be_3\n4    0.748457     0.511262  0.672645    0.849919  0.819849  id_00073f8be_4","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>reactivity</th>\n      <th>deg_Mg_pH10</th>\n      <th>deg_pH10</th>\n      <th>deg_Mg_50C</th>\n      <th>deg_50C</th>\n      <th>id_seqpos</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.813204</td>\n      <td>0.738167</td>\n      <td>1.892738</td>\n      <td>0.613165</td>\n      <td>0.810794</td>\n      <td>id_00073f8be_0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2.503969</td>\n      <td>3.582739</td>\n      <td>4.504695</td>\n      <td>3.598233</td>\n      <td>2.934643</td>\n      <td>id_00073f8be_1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1.264525</td>\n      <td>0.555534</td>\n      <td>0.651592</td>\n      <td>0.724087</td>\n      <td>0.663601</td>\n      <td>id_00073f8be_2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1.115623</td>\n      <td>0.917757</td>\n      <td>1.156807</td>\n      <td>1.523429</td>\n      <td>1.525713</td>\n      <td>id_00073f8be_3</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.748457</td>\n      <td>0.511262</td>\n      <td>0.672645</td>\n      <td>0.849919</td>\n      <td>0.819849</td>\n      <td>id_00073f8be_4</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"**Now we do the same for the LSTM model so we can blend their predictions:**"},{"metadata":{"trusted":true},"cell_type":"code","source":"preds_lstm = []\n\nfor df, preds in [(public_df, lstm_public_preds), (private_df, lstm_private_preds)]:\n    for i, uid in enumerate(df.id):\n        single_pred = preds[i]\n\n        single_df = pd.DataFrame(single_pred, columns=target_cols)\n        single_df['id_seqpos'] = [f'{uid}_{x}' for x in range(single_df.shape[0])]\n\n        preds_lstm.append(single_df)\n\npreds_lstm_df = pd.concat(preds_lstm)\npreds_lstm_df.head()","execution_count":25,"outputs":[{"output_type":"execute_result","execution_count":25,"data":{"text/plain":"   reactivity  deg_Mg_pH10  deg_pH10  deg_Mg_50C   deg_50C       id_seqpos\n0    0.729518     0.669326  1.906504    0.548261  0.768921  id_00073f8be_0\n1    2.165667     3.136641  4.320129    3.364549  2.972424  id_00073f8be_1\n2    1.433603     0.462998  0.559417    0.564855  0.619762  id_00073f8be_2\n3    1.272654     1.085803  1.200453    1.639748  1.648433  id_00073f8be_3\n4    0.924945     0.573390  0.539607    0.850250  0.874479  id_00073f8be_4","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>reactivity</th>\n      <th>deg_Mg_pH10</th>\n      <th>deg_pH10</th>\n      <th>deg_Mg_50C</th>\n      <th>deg_50C</th>\n      <th>id_seqpos</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.729518</td>\n      <td>0.669326</td>\n      <td>1.906504</td>\n      <td>0.548261</td>\n      <td>0.768921</td>\n      <td>id_00073f8be_0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2.165667</td>\n      <td>3.136641</td>\n      <td>4.320129</td>\n      <td>3.364549</td>\n      <td>2.972424</td>\n      <td>id_00073f8be_1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1.433603</td>\n      <td>0.462998</td>\n      <td>0.559417</td>\n      <td>0.564855</td>\n      <td>0.619762</td>\n      <td>id_00073f8be_2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1.272654</td>\n      <td>1.085803</td>\n      <td>1.200453</td>\n      <td>1.639748</td>\n      <td>1.648433</td>\n      <td>id_00073f8be_3</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.924945</td>\n      <td>0.573390</td>\n      <td>0.539607</td>\n      <td>0.850250</td>\n      <td>0.874479</td>\n      <td>id_00073f8be_4</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"For hyb1:"},{"metadata":{"trusted":true},"cell_type":"code","source":"preds_hyb1 = []\n\nfor df, preds in [(public_df, hyb1_public_preds), (private_df, hyb1_private_preds)]:\n    for i, uid in enumerate(df.id):\n        single_pred = preds[i]\n\n        single_df = pd.DataFrame(single_pred, columns=target_cols)\n        single_df['id_seqpos'] = [f'{uid}_{x}' for x in range(single_df.shape[0])]\n\n        preds_hyb1.append(single_df)\n\npreds_hyb1_df = pd.concat(preds_hyb1)\npreds_hyb1_df.head()","execution_count":26,"outputs":[{"output_type":"execute_result","execution_count":26,"data":{"text/plain":"   reactivity  deg_Mg_pH10  deg_pH10  deg_Mg_50C   deg_50C       id_seqpos\n0    0.777582     0.662388  1.874840    0.558371  0.776229  id_00073f8be_0\n1    2.330886     3.043195  3.881663    3.145874  2.651846  id_00073f8be_1\n2    1.377723     0.471362  0.578500    0.510297  0.548768  id_00073f8be_2\n3    1.211197     1.089980  1.223212    1.603461  1.615322  id_00073f8be_3\n4    0.835530     0.573457  0.632227    0.792810  0.815213  id_00073f8be_4","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>reactivity</th>\n      <th>deg_Mg_pH10</th>\n      <th>deg_pH10</th>\n      <th>deg_Mg_50C</th>\n      <th>deg_50C</th>\n      <th>id_seqpos</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.777582</td>\n      <td>0.662388</td>\n      <td>1.874840</td>\n      <td>0.558371</td>\n      <td>0.776229</td>\n      <td>id_00073f8be_0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2.330886</td>\n      <td>3.043195</td>\n      <td>3.881663</td>\n      <td>3.145874</td>\n      <td>2.651846</td>\n      <td>id_00073f8be_1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1.377723</td>\n      <td>0.471362</td>\n      <td>0.578500</td>\n      <td>0.510297</td>\n      <td>0.548768</td>\n      <td>id_00073f8be_2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1.211197</td>\n      <td>1.089980</td>\n      <td>1.223212</td>\n      <td>1.603461</td>\n      <td>1.615322</td>\n      <td>id_00073f8be_3</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.835530</td>\n      <td>0.573457</td>\n      <td>0.632227</td>\n      <td>0.792810</td>\n      <td>0.815213</td>\n      <td>id_00073f8be_4</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"For Hyb2"},{"metadata":{"trusted":true},"cell_type":"code","source":"preds_hyb2 = []\n\nfor df, preds in [(public_df, hyb2_public_preds), (private_df, hyb2_private_preds)]:\n    for i, uid in enumerate(df.id):\n        single_pred = preds[i]\n\n        single_df = pd.DataFrame(single_pred, columns=target_cols)\n        single_df['id_seqpos'] = [f'{uid}_{x}' for x in range(single_df.shape[0])]\n\n        preds_hyb2.append(single_df)\n\npreds_hyb2_df = pd.concat(preds_hyb2)\npreds_hyb2_df.head()","execution_count":27,"outputs":[{"output_type":"execute_result","execution_count":27,"data":{"text/plain":"   reactivity  deg_Mg_pH10  deg_pH10  deg_Mg_50C   deg_50C       id_seqpos\n0    0.829607     0.825044  2.147527    0.652266  0.810475  id_00073f8be_0\n1    2.374135     3.123879  4.387527    3.341963  2.847752  id_00073f8be_1\n2    1.690504     0.692595  0.790801    0.756798  0.754297  id_00073f8be_2\n3    1.344921     1.217306  1.306061    1.819828  1.719311  id_00073f8be_3\n4    0.894565     0.727556  0.659258    1.000475  0.865430  id_00073f8be_4","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>reactivity</th>\n      <th>deg_Mg_pH10</th>\n      <th>deg_pH10</th>\n      <th>deg_Mg_50C</th>\n      <th>deg_50C</th>\n      <th>id_seqpos</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.829607</td>\n      <td>0.825044</td>\n      <td>2.147527</td>\n      <td>0.652266</td>\n      <td>0.810475</td>\n      <td>id_00073f8be_0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2.374135</td>\n      <td>3.123879</td>\n      <td>4.387527</td>\n      <td>3.341963</td>\n      <td>2.847752</td>\n      <td>id_00073f8be_1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1.690504</td>\n      <td>0.692595</td>\n      <td>0.790801</td>\n      <td>0.756798</td>\n      <td>0.754297</td>\n      <td>id_00073f8be_2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1.344921</td>\n      <td>1.217306</td>\n      <td>1.306061</td>\n      <td>1.819828</td>\n      <td>1.719311</td>\n      <td>id_00073f8be_3</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.894565</td>\n      <td>0.727556</td>\n      <td>0.659258</td>\n      <td>1.000475</td>\n      <td>0.865430</td>\n      <td>id_00073f8be_4</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"For hyb3"},{"metadata":{"trusted":true},"cell_type":"code","source":"preds_hyb3 = []\n\nfor df, preds in [(public_df, hyb3_public_preds), (private_df, hyb3_private_preds)]:\n    for i, uid in enumerate(df.id):\n        single_pred = preds[i]\n\n        single_df = pd.DataFrame(single_pred, columns=target_cols)\n        single_df['id_seqpos'] = [f'{uid}_{x}' for x in range(single_df.shape[0])]\n\n        preds_hyb3.append(single_df)\n\npreds_hyb3_df = pd.concat(preds_hyb3)\npreds_hyb3_df.head()","execution_count":28,"outputs":[{"output_type":"execute_result","execution_count":28,"data":{"text/plain":"   reactivity  deg_Mg_pH10  deg_pH10  deg_Mg_50C   deg_50C       id_seqpos\n0    0.844596     0.677750  1.975148    0.526269  0.727702  id_00073f8be_0\n1    2.273908     3.147098  4.132948    3.163097  2.713194  id_00073f8be_1\n2    1.301402     0.473965  0.612442    0.659649  0.691871  id_00073f8be_2\n3    1.314000     1.095895  1.178771    1.573259  1.464372  id_00073f8be_3\n4    0.878311     0.520592  0.565562    0.800511  0.863788  id_00073f8be_4","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>reactivity</th>\n      <th>deg_Mg_pH10</th>\n      <th>deg_pH10</th>\n      <th>deg_Mg_50C</th>\n      <th>deg_50C</th>\n      <th>id_seqpos</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.844596</td>\n      <td>0.677750</td>\n      <td>1.975148</td>\n      <td>0.526269</td>\n      <td>0.727702</td>\n      <td>id_00073f8be_0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2.273908</td>\n      <td>3.147098</td>\n      <td>4.132948</td>\n      <td>3.163097</td>\n      <td>2.713194</td>\n      <td>id_00073f8be_1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1.301402</td>\n      <td>0.473965</td>\n      <td>0.612442</td>\n      <td>0.659649</td>\n      <td>0.691871</td>\n      <td>id_00073f8be_2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1.314000</td>\n      <td>1.095895</td>\n      <td>1.178771</td>\n      <td>1.573259</td>\n      <td>1.464372</td>\n      <td>id_00073f8be_3</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.878311</td>\n      <td>0.520592</td>\n      <td>0.565562</td>\n      <td>0.800511</td>\n      <td>0.863788</td>\n      <td>id_00073f8be_4</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"**And now we blend:**"},{"metadata":{"trusted":true},"cell_type":"code","source":"blend_preds_df = pd.DataFrame()\nblend_preds_df['id_seqpos'] = preds_gru_df['id_seqpos']\nblend_preds_df['reactivity'] = 0.2*preds_gru_df['reactivity'] + 0.2*preds_lstm_df['reactivity'] + 0.2*preds_hyb1_df['reactivity'] + 0.2*preds_hyb2_df['reactivity'] + 0.2*preds_hyb3_df['reactivity']\nblend_preds_df['deg_Mg_pH10'] = 0.2*preds_gru_df['deg_Mg_pH10'] + 0.2*preds_lstm_df['deg_Mg_pH10'] + 0.2*preds_hyb1_df['deg_Mg_pH10'] + 0.2*preds_hyb2_df['deg_Mg_pH10'] + 0.2*preds_hyb3_df['deg_Mg_pH10']\nblend_preds_df['deg_pH10'] = 0.2*preds_gru_df['deg_pH10'] + 0.2*preds_lstm_df['deg_pH10'] + 0.2*preds_hyb1_df['deg_pH10'] + 0.2*preds_hyb2_df['deg_pH10'] + 0.2*preds_hyb3_df['deg_pH10']\nblend_preds_df['deg_Mg_50C'] = 0.2*preds_gru_df['deg_Mg_50C'] + 0.2*preds_lstm_df['deg_Mg_50C'] + 0.2*preds_hyb1_df['deg_Mg_50C'] + 0.2*preds_hyb2_df['deg_Mg_50C'] + 0.2*preds_hyb3_df['deg_Mg_50C']\nblend_preds_df['deg_50C'] = 0.2*preds_gru_df['deg_50C'] + 0.2*preds_lstm_df['deg_50C'] + 0.2*preds_hyb1_df['deg_50C'] + 0.2*preds_hyb2_df['deg_Mg_50C'] + 0.2*preds_hyb3_df['deg_Mg_50C']","execution_count":29,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission = sample_sub[['id_seqpos']].merge(blend_preds_df, on=['id_seqpos'])\n\n#sanity check\nsubmission.head()","execution_count":30,"outputs":[{"output_type":"execute_result","execution_count":30,"data":{"text/plain":"        id_seqpos  reactivity  deg_Mg_pH10  deg_pH10  deg_Mg_50C   deg_50C\n0  id_00073f8be_0    0.798901     0.714535  1.959352    0.579667  0.706896\n1  id_00073f8be_1    2.329713     3.206710  4.245393    3.322743  3.012795\n2  id_00073f8be_2    1.413551     0.531291  0.638550    0.643137  0.649716\n3  id_00073f8be_3    1.251679     1.081348  1.213061    1.631945  1.636511\n4  id_00073f8be_4    0.856362     0.581251  0.613860    0.858793  0.862105","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id_seqpos</th>\n      <th>reactivity</th>\n      <th>deg_Mg_pH10</th>\n      <th>deg_pH10</th>\n      <th>deg_Mg_50C</th>\n      <th>deg_50C</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>id_00073f8be_0</td>\n      <td>0.798901</td>\n      <td>0.714535</td>\n      <td>1.959352</td>\n      <td>0.579667</td>\n      <td>0.706896</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>id_00073f8be_1</td>\n      <td>2.329713</td>\n      <td>3.206710</td>\n      <td>4.245393</td>\n      <td>3.322743</td>\n      <td>3.012795</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>id_00073f8be_2</td>\n      <td>1.413551</td>\n      <td>0.531291</td>\n      <td>0.638550</td>\n      <td>0.643137</td>\n      <td>0.649716</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>id_00073f8be_3</td>\n      <td>1.251679</td>\n      <td>1.081348</td>\n      <td>1.213061</td>\n      <td>1.631945</td>\n      <td>1.636511</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>id_00073f8be_4</td>\n      <td>0.856362</td>\n      <td>0.581251</td>\n      <td>0.613860</td>\n      <td>0.858793</td>\n      <td>0.862105</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission.to_csv('submission.csv', index=False)\nprint('Submission saved')","execution_count":31,"outputs":[{"output_type":"stream","text":"Submission saved\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}