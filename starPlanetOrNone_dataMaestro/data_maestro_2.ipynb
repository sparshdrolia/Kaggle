{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"from bayes_opt import BayesianOptimization\nfrom xgboost import XGBRegressor\nfrom sklearn.model_selection import StratifiedKFold, KFold\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn import metrics\n\n###############################################\n# Import Miscellaneous Assets\n###############################################\nimport numpy as np\n\n# Data manipulation\nimport pandas as pd\nimport numpy as np\n\n# Modeling\nimport lightgbm as lgb\n\n# Evaluation of the model\nfrom sklearn.model_selection import KFold, train_test_split\nfrom sklearn.metrics import roc_auc_score\n\n# Visualization\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport warnings\nwarnings.simplefilter(action='ignore', category=FutureWarning)\nfrom pandas.plotting import scatter_matrix\n%matplotlib inline\n\n\nfrom sklearn.feature_selection import SelectKBest\nfrom sklearn.feature_selection import chi2\n\nfrom dateutil.parser import parse\nfrom datetime import datetime\nfrom scipy.stats import norm\n\n# import all what you need for machine learning\nimport sklearn\nfrom sklearn.model_selection import cross_val_predict\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import cross_validate\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.model_selection import RandomizedSearchCV\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.preprocessing import RobustScaler\nimport warnings\nfrom datetime import datetime\nfrom functools import partial\nfrom pprint import pprint as pp\nfrom tqdm import tqdm, tqdm_notebook\n\nimport tensorflow as tf\nimport math\nfrom hyperopt import hp\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.externals import joblib\n\nimport xgboost as xgb\nfrom sklearn.metrics import accuracy_score\n\nfrom numpy import loadtxt\nfrom xgboost import XGBClassifier\n\nimport lightgbm as lgb\nfrom hyperopt import STATUS_OK\n\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Activation, Dropout\nfrom keras import optimizers\n\nfrom sklearn.metrics import accuracy_score\nimport os\nfrom sklearn import preprocessing\n\n\n###### ESSIENTIAL CODE ###########\ntrain = pd.read_csv(\"/kaggle/input/datamaestro2020/astro_train.csv\")\ntest = pd.read_csv(\"/kaggle/input/datamaestro2020/astro_test.csv\")\nsample = pd.read_csv(\"/kaggle/input/datamaestro2020/sample_submission.csv\")\n\n### useless thing ifigured all out in different notebook, data_maestro_1 dekho ab\ndel train[\"id\"]\ndel test[\"id\"]\n\ndel train[\"rerun\"]\ndel test[\"rerun\"]\ndel train[\"skyVersion\"]\ndel test[\"skyVersion\"]\ndel train[\"run\"]\ndel test[\"run\"]\ndel train[\"camCol\"]\ndel test[\"camCol\"]\n\n### minmax scaling karna hai but it get converted to different data type \n### bhavika tera manually kiya hua function bhej lol\n\ntrain.to_csv('train_new.csv', header=True, index=False)\ntest.to_csv('test_new.csv', header=True, index=False)\n\n","execution_count":101,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import h2o\nfrom h2o.estimators.gbm import H2OGradientBoostingEstimator\nfrom bayes_opt import BayesianOptimization\nh2o.init()\nh2o.remove_all()","execution_count":102,"outputs":[{"output_type":"stream","text":"Checking whether there is an H2O instance running at http://localhost:54321 . connected.\n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"--------------------------  ------------------------------------------------------------------\nH2O cluster uptime:         31 mins 52 secs\nH2O cluster timezone:       Etc/UTC\nH2O data parsing timezone:  UTC\nH2O cluster version:        3.28.0.4\nH2O cluster version age:    19 days\nH2O cluster name:           H2O_from_python_unknownUser_1mu23a\nH2O cluster total nodes:    1\nH2O cluster free memory:    2.827 Gb\nH2O cluster total cores:    2\nH2O cluster allowed cores:  2\nH2O cluster status:         locked, healthy\nH2O connection url:         http://localhost:54321\nH2O connection proxy:       {'http': None, 'https': None}\nH2O internal security:      False\nH2O API Extensions:         Amazon S3, XGBoost, Algos, AutoML, Core V3, TargetEncoder, Core V4\nPython version:             3.6.6 final\n--------------------------  ------------------------------------------------------------------","text/html":"<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td>H2O cluster uptime:</td>\n<td>31 mins 52 secs</td></tr>\n<tr><td>H2O cluster timezone:</td>\n<td>Etc/UTC</td></tr>\n<tr><td>H2O data parsing timezone:</td>\n<td>UTC</td></tr>\n<tr><td>H2O cluster version:</td>\n<td>3.28.0.4</td></tr>\n<tr><td>H2O cluster version age:</td>\n<td>19 days </td></tr>\n<tr><td>H2O cluster name:</td>\n<td>H2O_from_python_unknownUser_1mu23a</td></tr>\n<tr><td>H2O cluster total nodes:</td>\n<td>1</td></tr>\n<tr><td>H2O cluster free memory:</td>\n<td>2.827 Gb</td></tr>\n<tr><td>H2O cluster total cores:</td>\n<td>2</td></tr>\n<tr><td>H2O cluster allowed cores:</td>\n<td>2</td></tr>\n<tr><td>H2O cluster status:</td>\n<td>locked, healthy</td></tr>\n<tr><td>H2O connection url:</td>\n<td>http://localhost:54321</td></tr>\n<tr><td>H2O connection proxy:</td>\n<td>{'http': None, 'https': None}</td></tr>\n<tr><td>H2O internal security:</td>\n<td>False</td></tr>\n<tr><td>H2O API Extensions:</td>\n<td>Amazon S3, XGBoost, Algos, AutoML, Core V3, TargetEncoder, Core V4</td></tr>\n<tr><td>Python version:</td>\n<td>3.6.6 final</td></tr></table></div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = h2o.upload_file(\"/kaggle/working/train_new.csv\")\ntrain_cols = [x for x in data.col_names if x not in ['class']]\ntarget = \"class\"\ntrain, test = data.split_frame(ratios=[0.7])","execution_count":103,"outputs":[{"output_type":"stream","text":"Parse progress: |█████████████████████████████████████████████████████████| 100%\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"def train_model(max_depth, \n                ntrees,\n                min_rows, \n                learn_rate, \n                sample_rate, \n                col_sample_rate):\n    params = {\n        'max_depth': int(max_depth),\n        'ntrees': int(ntrees),\n        'min_rows': int(min_rows),\n        'learn_rate':learn_rate,\n        'sample_rate':sample_rate,\n        'col_sample_rate':col_sample_rate\n    }\n    model = H2OGradientBoostingEstimator(nfolds=5,**params)\n    model.train(x=train_cols, y=target, training_frame=train)\n    return -model.rmse()","execution_count":104,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"bounds = {\n    'max_depth':(3,8),\n    'ntrees': (100,500),\n    'min_rows':(10,30),\n    'learn_rate':(0.001, 0.01),\n    'sample_rate':(0.5,0.8),\n    'col_sample_rate':(0.5,0.8)\n}","execution_count":105,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"optimizer = BayesianOptimization(\n    f=train_model,\n    pbounds=bounds,\n    random_state=1,\n)\noptimizer.maximize(init_points=10, n_iter=1)\n# n_iter = 50 #basic","execution_count":106,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"optimizer.max","execution_count":107,"outputs":[{"output_type":"execute_result","execution_count":107,"data":{"text/plain":"{}"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"#set manually to optimiser.max idk how to do directly cheap trick lol\n#maxdepth and ntrees int karaychi approx\n\n#defining\nmodel = H2OGradientBoostingEstimator(nfolds=5, \n                                     col_sample_rate= 0.5558780634133013,\n                                     learn_rate = 0.00411004654338743,\n                                     max_depth = 7,\n                                     min_rows  = 20.776334680067137,\n                                     ntrees = 268,\n                                     sample_rate = 0.7055658501190278\n                                    )\n\n#traneeeee\nmodel.train(x=train_cols, y=target, training_frame=train)","execution_count":108,"outputs":[{"output_type":"stream","text":"gbm Model Build progress: |███████████████████████████████████████████████| 100%\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"#test = pd.read_csv(\"/kaggle/input/datamaestro2020/astro_test.csv\")\n\ntest = h2o.upload_file(\"/kaggle/working/test_new.csv\")\n\n#test = h2o.H2OFrame(test)","execution_count":100,"outputs":[{"output_type":"stream","text":"Parse progress: |█████████████████████████████████████████████████████████| 100%\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"#a lotta random convesions here which i tuk too long to figar out\n\npredictions = model.predict(test)\npdr = predictions.as_data_frame().to_numpy()\np = np.round(pdr).astype(int)\n\n#allah ho gaya finally\n\nsubmission_df = pd.DataFrame(columns=['id', 'class'])\nsubmission_df['id'] = sample['id']\nsubmission_df['class'] = p\nsubmission_df.to_csv('bayesian.csv', header=True, index=False)\n\n#dekhlo ab kyahi, test noi banaya banana hai toh use own brain\nsubmission_df.head(10)","execution_count":97,"outputs":[{"output_type":"execute_result","execution_count":97,"data":{"text/plain":"       id  class\n0   45000      1\n1   45001      1\n2   45002      1\n3   45003      1\n4   45004      1\n..    ...    ...\n95  45095      1\n96  45096      0\n97  45097      1\n98  45098      1\n99  45099      1\n\n[100 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>class</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>45000</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>45001</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>45002</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>45003</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>45004</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>95</th>\n      <td>45095</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>96</th>\n      <td>45096</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>97</th>\n      <td>45097</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>98</th>\n      <td>45098</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>99</th>\n      <td>45099</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>100 rows × 2 columns</p>\n</div>"},"metadata":{}}]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}