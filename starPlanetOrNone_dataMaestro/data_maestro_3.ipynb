{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"from bayes_opt import BayesianOptimization\nfrom xgboost import XGBRegressor\nfrom sklearn.model_selection import StratifiedKFold, KFold\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn import metrics\n\n###############################################\n# Import Miscellaneous Assets\n###############################################\n# Data manipulation\nimport pandas as pd\nimport numpy as np\n\n# Modeling\nimport lightgbm as lgb\n\n# Evaluation of the model\nfrom sklearn.model_selection import KFold, train_test_split\nfrom sklearn.metrics import roc_auc_score\n\n# Visualization\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport warnings\nwarnings.simplefilter(action='ignore', category=FutureWarning)\nfrom pandas.plotting import scatter_matrix\n%matplotlib inline\n\n\nfrom sklearn.feature_selection import SelectKBest\nfrom sklearn.feature_selection import chi2\n\nfrom dateutil.parser import parse\nfrom datetime import datetime\nfrom scipy.stats import norm\n\n# import all what you need for machine learning\nimport sklearn\nfrom sklearn.model_selection import cross_val_predict\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import cross_validate\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.model_selection import RandomizedSearchCV\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.preprocessing import RobustScaler\nimport warnings\nfrom datetime import datetime\nfrom functools import partial\nfrom pprint import pprint as pp\nfrom tqdm import tqdm, tqdm_notebook\n\nimport tensorflow as tf\nimport math\nfrom hyperopt import hp\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.externals import joblib\n\nimport xgboost as xgb\nfrom sklearn.metrics import accuracy_score\n\nfrom numpy import loadtxt\nfrom xgboost import XGBClassifier\n\nimport lightgbm as lgb\nfrom hyperopt import STATUS_OK\n\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Activation, Dropout\nfrom keras import optimizers\n\nfrom sklearn.metrics import accuracy_score\nimport os\nfrom sklearn import preprocessing\n\nimport h2o\nfrom h2o.estimators import H2ORandomForestEstimator\nfrom h2o.estimators import H2OXGBoostEstimator\n###### ESSIENTIAL CODE ###########\ntrain = pd.read_csv(\"/kaggle/input/datamaestro2020/astro_train.csv\")\ntest = pd.read_csv(\"/kaggle/input/datamaestro2020/astro_test.csv\")\nsample = pd.read_csv(\"/kaggle/input/datamaestro2020/sample_submission.csv\")\n\n### useless thing ifigured all out in different notebook, data_maestro_1 dekho ab\ndel train[\"id\"]\ndel test[\"id\"]\n\ndel train[\"rerun\"]\ndel test[\"rerun\"]\ndel train[\"skyVersion\"]\ndel test[\"skyVersion\"]\ndel train[\"run\"]\ndel test[\"run\"]\ndel train[\"camCol\"]\ndel test[\"camCol\"]\n\n### minmax scaling karna hai but it gets converted to a different data type \n### bhavika tera manually kiya hua function bhej lol\n\ntrain.to_csv('train_new.csv', header=True, index=False)\ntest.to_csv('test_new.csv', header=True, index=False)","execution_count":53,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import h2o\nfrom h2o.estimators.gbm import H2OGradientBoostingEstimator\nfrom bayes_opt import BayesianOptimization\nh2o.init()\nh2o.remove_all()\n\ndata = h2o.upload_file(\"/kaggle/working/train_new.csv\")\ntrain_cols = [x for x in data.col_names if x not in ['class']]\ntarget = \"class\"\ntrain, test = data.split_frame(ratios=[0.7])","execution_count":54,"outputs":[{"output_type":"stream","text":"Checking whether there is an H2O instance running at http://localhost:54321 . connected.\n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"--------------------------  ------------------------------------------------------------------\nH2O cluster uptime:         1 hour 3 mins\nH2O cluster timezone:       Etc/UTC\nH2O data parsing timezone:  UTC\nH2O cluster version:        3.28.0.4\nH2O cluster version age:    19 days\nH2O cluster name:           H2O_from_python_unknownUser_uwpswn\nH2O cluster total nodes:    1\nH2O cluster free memory:    2.641 Gb\nH2O cluster total cores:    2\nH2O cluster allowed cores:  2\nH2O cluster status:         locked, healthy\nH2O connection url:         http://localhost:54321\nH2O connection proxy:       {'http': None, 'https': None}\nH2O internal security:      False\nH2O API Extensions:         Amazon S3, XGBoost, Algos, AutoML, Core V3, TargetEncoder, Core V4\nPython version:             3.6.6 final\n--------------------------  ------------------------------------------------------------------","text/html":"<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td>H2O cluster uptime:</td>\n<td>1 hour 3 mins</td></tr>\n<tr><td>H2O cluster timezone:</td>\n<td>Etc/UTC</td></tr>\n<tr><td>H2O data parsing timezone:</td>\n<td>UTC</td></tr>\n<tr><td>H2O cluster version:</td>\n<td>3.28.0.4</td></tr>\n<tr><td>H2O cluster version age:</td>\n<td>19 days </td></tr>\n<tr><td>H2O cluster name:</td>\n<td>H2O_from_python_unknownUser_uwpswn</td></tr>\n<tr><td>H2O cluster total nodes:</td>\n<td>1</td></tr>\n<tr><td>H2O cluster free memory:</td>\n<td>2.641 Gb</td></tr>\n<tr><td>H2O cluster total cores:</td>\n<td>2</td></tr>\n<tr><td>H2O cluster allowed cores:</td>\n<td>2</td></tr>\n<tr><td>H2O cluster status:</td>\n<td>locked, healthy</td></tr>\n<tr><td>H2O connection url:</td>\n<td>http://localhost:54321</td></tr>\n<tr><td>H2O connection proxy:</td>\n<td>{'http': None, 'https': None}</td></tr>\n<tr><td>H2O internal security:</td>\n<td>False</td></tr>\n<tr><td>H2O API Extensions:</td>\n<td>Amazon S3, XGBoost, Algos, AutoML, Core V3, TargetEncoder, Core V4</td></tr>\n<tr><td>Python version:</td>\n<td>3.6.6 final</td></tr></table></div>"},"metadata":{}},{"output_type":"stream","text":"Parse progress: |█████████████████████████████████████████████████████████| 100%\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"def train_model(learn_rate, \n                max_depth,\n                min_child_weight, \n                gamma,\n                colsample_bytree,\n                eta):\n    params = {\n        'learn_rate': learn_rate ,\n        'max_depth' :int(max_depth) ,\n        'min_child_weight' :int(min_child_weight) ,\n        'gamma' : gamma,\n        'colsample_bytree' : colsample_bytree,\n        'eta':eta\n    }\n    model = H2OXGBoostEstimator(nfolds=5,**params)\n    model.train(x=train_cols, y=target, training_frame=train)\n    return -model.rmse()","execution_count":64,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"bounds = {\n        'learn_rate': (0.01,0.3) ,\n        'max_depth' :(3,15) ,\n        'min_child_weight' :(1,7) ,\n        'gamma' : (0,0.4),\n        'colsample_bytree' : (0.3,1.0),\n        'eta':(0.01,0.2)\n    }","execution_count":65,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"optimizer = BayesianOptimization(\n    f=train_model,\n    pbounds=bounds,\n    random_state=1,\n)\noptimizer.maximize(init_points=10, n_iter=100)\n# n_iter = 50 #basic","execution_count":66,"outputs":[{"output_type":"stream","text":"|   iter    |  target   | colsam... |    eta    |   gamma   | learn_... | max_depth | min_ch... |\n-------------------------------------------------------------------------------------------------\nxgboost Model Build progress: |███████████████████████████████████████████| 100%\n|  1        | -0.664    |  0.5919   |  0.1469   |  4.575e-0 |  0.09768  |  4.761    |  1.554    |\nxgboost Model Build progress: |███████████████████████████████████████████| 100%\n|  2        | -0.5978   |  0.4304   |  0.07566  |  0.1587   |  0.1663   |  8.03     |  5.111    |\nxgboost Model Build progress: |███████████████████████████████████████████| 100%\n|  3        | -0.5282   |  0.4431   |  0.1768   |  0.01096  |  0.2044   |  8.008    |  4.352    |\nxgboost Model Build progress: |███████████████████████████████████████████| 100%\n|  4        | -0.6733   |  0.3983   |  0.04764  |  0.3203   |  0.2908   |  6.761    |  5.154    |\nxgboost Model Build progress: |███████████████████████████████████████████| 100%\n|  5        | -0.6339   |  0.9135   |  0.18     |  0.03402  |  0.02133  |  5.038    |  6.269    |\nxgboost Model Build progress: |███████████████████████████████████████████| 100%\n|  6        | -0.4298   |  0.3688   |  0.09001  |  0.3832   |  0.1646   |  11.3     |  2.893    |\nxgboost Model Build progress: |███████████████████████████████████████████| 100%\n|  7        | -0.2017   |  0.7806   |  0.1686   |  0.007315 |  0.2275   |  14.87    |  5.489    |\nxgboost Model Build progress: |██ (cancelled)\n","name":"stdout"},{"output_type":"error","ename":"H2OJobCancelled","evalue":"Job<$03017f00000132d4ffffffff$_aae870d11ee66b97970787b12f5c442b> was cancelled by the user.","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/bayes_opt/target_space.py\u001b[0m in \u001b[0;36mprobe\u001b[0;34m(self, params)\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 191\u001b[0;31m             \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0m_hashable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    192\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyError\u001b[0m: (0.49631079444508364, 0.15996307240578284, 0.041290402631056815, 0.1398891225910125, 13.903146037117146, 2.761684890242077)","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mH2OJobCancelled\u001b[0m                           Traceback (most recent call last)","\u001b[0;32m<ipython-input-66-b407f1fdf833>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m )\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaximize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minit_points\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;31m# n_iter = 50 #basic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/bayes_opt/bayesian_optimization.py\u001b[0m in \u001b[0;36mmaximize\u001b[0;34m(self, init_points, n_iter, acq, kappa, xi, **gp_params)\u001b[0m\n\u001b[1;32m    172\u001b[0m                 \u001b[0miteration\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 174\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprobe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_probe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlazy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    175\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEvents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOPTIMIZATION_END\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/bayes_opt/bayesian_optimization.py\u001b[0m in \u001b[0;36mprobe\u001b[0;34m(self, params, lazy)\u001b[0m\n\u001b[1;32m    110\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_space\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprobe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    113\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEvents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOPTIMIZATION_STEP\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/bayes_opt/target_space.py\u001b[0m in \u001b[0;36mprobe\u001b[0;34m(self, params)\u001b[0m\n\u001b[1;32m    192\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m             \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_keys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 194\u001b[0;31m             \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    195\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-64-2aecc2576978>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(learn_rate, max_depth, min_child_weight, gamma, colsample_bytree, eta)\u001b[0m\n\u001b[1;32m     14\u001b[0m     }\n\u001b[1;32m     15\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mH2OXGBoostEstimator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnfolds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_cols\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_frame\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrmse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/h2o/estimators/estimator_base.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, x, y, training_frame, offset_column, fold_column, weights_column, validation_frame, max_runtime_secs, ignored_columns, model_id, verbose)\u001b[0m\n\u001b[1;32m    110\u001b[0m         self._train(x=x, y=y, training_frame=training_frame, offset_column=offset_column, fold_column=fold_column,\n\u001b[1;32m    111\u001b[0m                     \u001b[0mweights_column\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mweights_column\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_frame\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_frame\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_runtime_secs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_runtime_secs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m                     ignored_columns=ignored_columns, model_id=model_id, verbose=verbose)\n\u001b[0m\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/h2o/estimators/estimator_base.py\u001b[0m in \u001b[0;36m_train\u001b[0;34m(self, x, y, training_frame, offset_column, fold_column, weights_column, validation_frame, max_runtime_secs, ignored_columns, model_id, verbose, extend_parms_fn)\u001b[0m\n\u001b[1;32m    263\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 265\u001b[0;31m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpoll_updates\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_print_model_scoring_history\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mverbose\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    266\u001b[0m         \u001b[0mmodel_json\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh2o\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"GET /%d/Models/%s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mrest_ver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdest_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"models\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_resolve_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdest_key\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_json\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/h2o/job.py\u001b[0m in \u001b[0;36mpoll\u001b[0;34m(self, poll_updates)\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0;31m# check if failed... and politely print relevant message\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"CANCELLED\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mH2OJobCancelled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Job<%s> was cancelled by the user.\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjob_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"FAILED\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"stacktrace\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mH2OJobCancelled\u001b[0m: Job<$03017f00000132d4ffffffff$_aae870d11ee66b97970787b12f5c442b> was cancelled by the user."]}]},{"metadata":{"trusted":true},"cell_type":"code","source":"optimizer.max","execution_count":67,"outputs":[{"output_type":"execute_result","execution_count":67,"data":{"text/plain":"{'target': -0.2016664166253024,\n 'params': {'colsample_bytree': 0.7805506493771085,\n  'eta': 0.16857887766050086,\n  'gamma': 0.007315310937676723,\n  'learn_rate': 0.22754185133404056,\n  'max_depth': 14.866333066877937,\n  'min_child_weight': 5.488993926279036}}"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"#set manually to optimiser.max idk how to do directly cheap trick lol\n#maxdepth and ntrees int karaychi approx\n\n#defining\nmodel = H2OXGBoostEstimator(colsample_bytree=0.7805506493771085, \n                                     eta = 0.16857887766050086,\n                                     gamma  = 0.007315310937676723,\n                                     learn_rate = 0.22754185133404056,\n                                     max_depth = 15,\n                                     min_child_weight = 5\n                                    )\n\n#traneeeee\nmodel.train(x=train_cols, y=target, training_frame=train)","execution_count":68,"outputs":[{"output_type":"stream","text":"xgboost Model Build progress: |███████████████████████████████████████████| 100%\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"test = h2o.upload_file(\"/kaggle/working/test_new.csv\")","execution_count":69,"outputs":[{"output_type":"stream","text":"Parse progress: |█████████████████████████████████████████████████████████| 100%\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"#a lotta random convesions here which i tuk too long to figar out\n\npredictions = model.predict(test)\npdr = predictions.as_data_frame().to_numpy()\np = np.round(pdr).astype(int)\n\n#allah ho gaya finally\n\nsubmission_df = pd.DataFrame(columns=['id', 'class'])\nsubmission_df['id'] = sample['id']\nsubmission_df['class'] = p\nsubmission_df.to_csv('bayesian.csv', header=True, index=False)\n\n#dekhlo ab kyahi, test noi banaya banana hai toh use own brain\nsubmission_df.head(100)","execution_count":71,"outputs":[{"output_type":"stream","text":"xgboost prediction progress: |████████████████████████████████████████████| 100%\n","name":"stdout"},{"output_type":"execute_result","execution_count":71,"data":{"text/plain":"       id  class\n0   45000      1\n1   45001      0\n2   45002      1\n3   45003      0\n4   45004      1\n..    ...    ...\n95  45095      1\n96  45096      0\n97  45097      1\n98  45098      1\n99  45099      1\n\n[100 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>class</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>45000</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>45001</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>45002</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>45003</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>45004</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>95</th>\n      <td>45095</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>96</th>\n      <td>45096</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>97</th>\n      <td>45097</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>98</th>\n      <td>45098</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>99</th>\n      <td>45099</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>100 rows × 2 columns</p>\n</div>"},"metadata":{}}]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}